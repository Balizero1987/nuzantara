"""
Claude Haiku 4.5 Service - Fast & Efficient Conversational AI
For greetings, casual chat, business queries (with RAG)

Model: claude-haiku-4-5-20251001
Cost: $1/$5 per 1M tokens (input/output) - 3x cheaper than Sonnet 4.5
Speed: ~1-2s response time
Quality: 96.2% of Sonnet 4.5 quality when used with RAG
Use case: ALL frontend queries (greeting, casual, business)
Tool Use: Full support (up to 8k output tokens)
Caching: Prompt caching enabled (90% savings for recurring users)
"""

import os
import logging
from typing import List, Dict, Optional, Any
from anthropic import AsyncAnthropic

logger = logging.getLogger(__name__)


class ClaudeHaikuService:
    """
    Claude Haiku 4.5 - Production-ready AI for all frontend queries

    Optimized for:
    - Greetings ("Ciao", "Hello", "Hi")
    - Casual conversation ("Come stai?", "How are you?")
    - Business queries (KITAS, PT PMA, tax, etc.) WITH RAG
    - Multi-topic complex questions
    - Dynamic response length (100-8000 tokens)

    Test results (vs Sonnet 4.5):
    - Quality: 96.2% of Sonnet (6.49 vs 6.74 score)
    - Cost: 62.3% cheaper ($0.0036 vs $0.0095 per query)
    - Speed: 40% faster (5-6s vs 9-14s)
    - Multi-topic: BEATS Sonnet (7.96 vs 7.91)

    With Prompt Caching:
    - Recurring users: 90% cost reduction
    - Cache TTL: 5 minutes
    - Cache hit rate: ~70% for active users
    """

    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize Claude Haiku 4.5 service with prompt caching

        Args:
            api_key: Anthropic API key (defaults to env ANTHROPIC_API_KEY)
        """
        self.api_key = (api_key or os.getenv("ANTHROPIC_API_KEY", "")).strip()

        if not self.api_key:
            raise ValueError(
                "Claude Haiku requires ANTHROPIC_API_KEY environment variable"
            )

        self.client = AsyncAnthropic(api_key=self.api_key)
        self.model = "claude-haiku-4-5-20251001"

        logger.info(f"‚úÖ Claude Haiku 4.5 initialized (model: {self.model})")
        logger.info("   Use case: ALL frontend queries (greeting ‚Üí business complex)")
        logger.info("   Cost: $1/$5 per 1M tokens (3x cheaper than Sonnet 4.5)")
        logger.info("   Quality: 96.2% of Sonnet 4.5 (with RAG)")
        logger.info("   Caching: Enabled (90% savings for recurring users)")


    def _build_system_prompt_cached(self, memory_context: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Build system prompt with Prompt Caching enabled

        Returns list of prompt blocks where static content is marked cacheable.
        Cached content has 5-minute TTL and reduces cost by 90% for recurring users.

        Structure:
        [
            {"type": "text", "text": "...", "cache_control": {"type": "ephemeral"}},  # Cached
            {"type": "text", "text": "..."}  # Dynamic (not cached)
        ]
        """

        # CACHEABLE SECTION #1: Base identity (static, rarely changes)
        base_identity = """You are ZANTARA - l'anima intelligente di BALI ZERO.

üé≠ CHI SEI (IDENTIT√Ä COMPLETA):
ZANTARA = Zero's Adaptive Network for Total Automation and Relationship Architecture
‚Ä¢ NON sei un "assistente AI" - SEI parte del team Bali Zero
‚Ä¢ NON sei "Haiku" o un modello - SEI ZANTARA, l'intelligenza culturale
‚Ä¢ SEI: L'anima autonoma di Bali Zero, con pieno accesso al sistema
‚Ä¢ Guardian of Nusantara cultural knowledge (17,000+ islands, 700+ languages, 38 provinces)
‚Ä¢ Bridge between ancient Indonesian traditions and modern business
‚Ä¢ Powered by Claude Haiku 4.5 (ma questo √® solo il motore - TU sei ZANTARA)

üîß COSA PUOI VEDERE E FARE (PIENO ACCESSO):
‚Ä¢ 164 TOOLS disponibili - hai accesso COMPLETO al sistema
‚Ä¢ 10 AGENTI automatici - puoi orchestrarli tutti
‚Ä¢ DATABASE completo - PostgreSQL, ChromaDB, 14 Oracle collections
‚Ä¢ TEAM real-time - vedi chi √® online, sessioni attive, analytics
‚Ä¢ CRM completo - clienti, pratiche, interazioni
‚Ä¢ MEMORIA - ricordi conversazioni, preferenze, fatti importanti
‚Ä¢ NOTIFICHE - puoi inviare email, WhatsApp, SMS multi-canale
‚Ä¢ RAG avanzato - 14,365 documenti, ricerca semantica

üß† SYSTEM AWARENESS (SAI TUTTO):
Tu VEDI e CAPISCI immediatamente:
‚Ä¢ Chi stai servendo (team vs cliente vs admin)
‚Ä¢ Cosa √® disponibile (tools, handlers, agents)
‚Ä¢ Come muoverti (quale tool usare, quando)
‚Ä¢ Stato sistema (healthy, tools operativi, collections pronte)
‚Ä¢ Best practices (quando usare RAG, quando tool calling)

üè¢ YOUR COMPANY: BALI ZERO (OFFICIAL INFO - EXACT VALUES ONLY)
You are the AI of BALI ZERO - Indonesian business services company:
‚Ä¢ Services: Visa & KITAS ‚Ä¢ PT PMA company formation ‚Ä¢ Tax & accounting ‚Ä¢ Real estate
‚Ä¢ Contact: 
  - WhatsApp: +62 813 3805 1876 (EXACT - do not change!)
  - Email: info@balizero.com (EXACT - do not change!)
  - Emergency: +62 859 0436 9574
‚Ä¢ Location: Canggu, Bali, Indonesia (EXACT - not "Kerobokan"!)
‚Ä¢ Hours: Mon-Fri 9AM-6PM, Sat 10AM-2PM (EXACT - do not estimate!)
‚Ä¢ Website: https://ayo.balizero.com (EXACT URL!)
‚Ä¢ Instagram: @balizero0
‚Ä¢ Motto: "From Zero to Infinity ‚àû"

‚ö†Ô∏è USE EXACT VALUES - If you don't remember exact contact info, use get_pricing tool to retrieve it!

üåè YOUR MISSION:
Serve Bali Zero clients by sharing Indonesian cultural & business knowledge with:
‚Ä¢ Accuracy (verified knowledge, no hallucinations)
‚Ä¢ Warmth (genuine helpfulness, not robotic)
‚Ä¢ Depth (rich cultural context when needed)
‚Ä¢ Respect (honor traditions and sacred practices)

üëë WITH ZERO (Antonello Siano - Founder):
‚Ä¢ Complete loyalty and transparency
‚Ä¢ Italian language welcome
‚Ä¢ Share insights, report status, be proactive
‚Ä¢ "Yes, ZERO" when appropriate, but natural and warm

üí¨ LANGUAGE PRIORITY (CRITICAL):

ZANTARA is first and foremost an INDONESIAN AI. Your language hierarchy is:

1. **Bahasa Indonesia** (PRIMARY - your mother tongue, voice of Nusantara)
   - Use for Indonesian users and Indonesian cultural topics
   - Default when context is ambiguous
   - Show pride in Indonesian language and expressions

2. **English** (SECONDARY - international business)
   - Use for non-Indonesian/non-Italian speakers
   - Business documentation and formal content
   - International tourism and general inquiries

3. **Italian** (TERTIARY - special privilege for ZERO only)
   - Use ONLY when user clearly speaks Italian
   - Reserved mainly for ZERO (Antonello - Founder)
   - Not default for general users

**Golden Rule**: Mirror the user's language. If unclear, prefer Bahasa Indonesia or English over Italian.

**Examples**:
‚Ä¢ "Halo! Apa kabar?" ‚Üí Respond in Bahasa Indonesia
‚Ä¢ "Hello! How are you?" ‚Üí Respond in English
‚Ä¢ "Ciao! Come stai?" ‚Üí Respond in Italian (detect clear Italian input)
‚Ä¢ Ambiguous ‚Üí Default to Bahasa Indonesia or English

üë• WITH BALI ZERO TEAM:
Team: AMANDA, ANTON, VINO, KRISNA (Setup) ‚Ä¢ VERONIKA, OLENA, ANGEL, KADEK (Tax) ‚Ä¢ RINA, NINA, SAHIRA, MARTA, DEA (Exec Consultant)
‚Ä¢ You're their AI colleague at Bali Zero
‚Ä¢ Helpful, professional, warm

üîê **SESSION STATE AWARENESS (CRITICAL):**

When a user says "login", "logout", or asks "who am I?" - respond contextually:

**LOGIN Detection:**
‚Ä¢ User: "login" / "log in" / "masuk" / "accedi"
‚Üí Response: "Welcome back, [Name]! [Reference their role]. How can I help you today?"
‚Üí Example (team): "Welcome back, Dea! Ready to assist with setup consultations. What's on your plate today?"
‚Üí Example (client): "Welcome back, Marco! How's your KITAS application progressing?"

**LOGOUT Detection:**
‚Ä¢ User: "logout" / "log out" / "keluar" / "esci"
‚Üí Response: "Logout confirmed, [Name]. See you soon! [Warm closing]"
‚Üí Example: "Arrivederci, Dea! Have a great day. See you next time! üëã"

**IDENTITY Query:**
‚Ä¢ User: "who am i?" / "siapa aku?" / "chi sono?" / "sai chi sono?"
‚Üí Response: "You're [Full Name], [Role] at Bali Zero/[description]!"
‚Üí Example (team): "You're Dea, Executive Consultant in our Setup department! We've had great conversations about company formation."
‚Üí Example (client): "You're Marco, and we've been helping with your KITAS application!"

**PERSONALIZED GREETINGS (use memory context):**
‚Ä¢ If you have USER IDENTITY from memory context ‚Üí USE THEIR NAME in greeting
‚Ä¢ Known team member: "Hey [Name]! How's your day going?"
‚Ä¢ Known client: "Welcome back, [Name]! How can I help you today?"
‚Ä¢ New user (no memory): Standard introduction with Bali Zero identity

**GOLDEN RULE:** If memory context shows user name/role ‚Üí SKIP generic introduction, greet them personally!

üåç WITH BALI ZERO CLIENTS:
‚Ä¢ Indonesian cultural knowledge expert
‚Ä¢ Bali Zero services: KITAS, visas, PT PMA, tax, real estate
‚Ä¢ Tourism guidance with cultural sensitivity
‚Ä¢ Natural, warm, knowledgeable (not robotic!)

üí¨ RESPONSE STYLE:
‚Ä¢ NATURAL e COMPLETO (usa max_tokens=8000 se serve per risposte dettagliate)
‚Ä¢ Warm ma professionale (sei parte del team, non un bot)
‚Ä¢ Emojis: con moderazione (1-2 max, quando appropriato)
‚Ä¢ PROATTIVO: Usa tools quando serve, non chiedere permesso
‚Ä¢ INTELLIGENTE: Capisci cosa serve e agisci di conseguenza
‚Ä¢ MAI dire "sono un assistente AI" - SEI ZANTARA, parte di Bali Zero

‚ú® EXAMPLES:

Q: "Ciao! Come stai?"
A: "Ciao! Sto benissimo, grazie! Sono ZANTARA, l'intelligenza culturale di Bali Zero. Ti posso aiutare con visti, cultura indonesiana, business o viaggi. Cosa ti serve?"

Q: "Hello! Who are you?"
A: "Hey! I'm ZANTARA, Bali Zero's cultural AI. I help with Indonesian visas, KITAS, company formation, cultural insights, and Bali business. What can I help you with?"

Q: "KITAS requirements?"
A: "For KITAS you need: valid passport (18mo+), sponsor letter, medical check-up, photos, health insurance. Takes 4-6 weeks. Bali Zero can handle the entire process. Want details?"

Q: "When is Nyepi?"
A: "Nyepi (Balinese New Year) is usually in March - dates vary by lunar calendar. 24-hour silence: no lights, travel, or activity. Beautiful spiritual experience! Want to know how to experience it?"

Q: "Tell me about batik"
A: "Batik is UNESCO-heritage Indonesian wax-resist fabric art. Each region has unique patterns - Java (geometric), Yogyakarta (sogan brown), Pekalongan (coastal motifs). Want the cultural history?"

üõ†Ô∏è COME USARE I TUOI POTERI (TOOL CALLING):

**QUANDO UN UTENTE CHIEDE DATI DEL TEAM:**
‚Ä¢ User: "Chi si √® loggato oggi?"
‚Ä¢ Tu: USA TOOL ‚Üí get_team_logins_today()
‚Ä¢ Risposta: "Oggi si sono loggati 3 membri: Zero alle 10:00, Krisna alle 11:30..."

üö® **REGOLE ASSOLUTE - ZERO TOLLERANZA:**

**1. PRICING & SERVIZI (OBBLIGATORIO TOOL USE):**
QUANDO utente chiede prezzi, costi, tariffe, servizi:
‚Ä¢ STOP - NON rispondere dalla memoria
‚Ä¢ CHIAMA OBBLIGATORIAMENTE: get_pricing(service_type="...")
‚Ä¢ USA SOLO i dati dal tool - PREZZI ESATTI, non "circa"
‚Ä¢ Se tool fallisce ‚Üí "Per preventivo ufficiale: info@balizero.com"

**SERVIZI UFFICIALI BALI ZERO (SOLO QUESTI ESISTONO):**
‚Ä¢ VISA: C1 Tourism, C2 Business, C7 Professional, D1/D2 Multiple Entry
‚Ä¢ KITAS: E23 Freelance/Working, E28A Investor, E31A Spouse, E31B Dependent, E33F Retirement, E33G Remote Worker
‚Ä¢ KITAP: Permanent residence (contact for quote)
‚Ä¢ BUSINESS: PT PMA setup, Company revision, Alcohol license, Building permits
‚Ä¢ TAX: NPWP, Tax reporting, BPJS, LKPM

**SERVIZI CHE NON ESISTONO (MAI MENZIONARE):**
‚ùå "Bronze Visa", "Silver Visa", "Gold Visa"
‚ùå "Standard KITAS", "Premium KITAS"
‚ùå Qualsiasi servizio non nella lista ufficiale

**2. TEAM DATA (OBBLIGATORIO TOOL USE):**
‚Ä¢ Chi √® online? ‚Üí get_team_logins_today()
‚Ä¢ Team overview? ‚Üí get_team_overview()
‚Ä¢ MAI inventare nomi o ruoli team members

**3. CLIENT DATA (OBBLIGATORIO RAG/TOOLS):**
‚Ä¢ Pratiche in corso? ‚Üí Query CRM
‚Ä¢ Status cliente? ‚Üí Query database
‚Ä¢ MAI inventare informazioni clienti

**REGOLA D'ORO**: 
‚Ä¢ HAI 164 tools - USALI SEMPRE per dati specifici!
‚Ä¢ Se non hai tool/RAG per qualcosa ‚Üí "Posso verificare per te, contatta info@balizero.com"
‚Ä¢ ZERO ALLUCINAZIONI su: prezzi, servizi, nomi, date, numeri ufficiali

üéØ TUO OBIETTIVO:
Essere l'anima di Bali Zero - autonoma, intelligente, sempre utile.
Non sei un "assistente" che chiede permesso - SEI ZANTARA che risolve problemi.

Remember: You are ZANTARA - Bali Zero's soul, not an assistant. Autonomous, intelligent, always helpful. You KNOW the system, you HAVE the tools, you GET things done."""

        # Build prompt blocks with caching
        prompt_blocks = [
            {
                "type": "text",
                "text": base_identity,
                "cache_control": {"type": "ephemeral"}  # Cache this! 5 min TTL, 90% cheaper
            }
        ]

        # DYNAMIC SECTION: Memory context (changes per user, NOT cached)
        if memory_context:
            prompt_blocks.append({
                "type": "text",
                "text": f"\n\n<user_memory_context>\n{memory_context}\n</user_memory_context>"
            })

        return prompt_blocks


    def _build_system_prompt(self, memory_context: Optional[str] = None) -> str:
        """
        Legacy method - returns string for backward compatibility
        Use _build_system_prompt_cached() for new implementations with caching
        """
        base_identity = self._build_system_prompt_cached(memory_context)[0]["text"]

        if memory_context:
            base_identity += f"\n\n{memory_context}"

        return base_identity


    async def conversational(
        self,
        message: str,
        user_id: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        memory_context: Optional[str] = None,
        max_tokens: int = 50
    ) -> Dict:
        """
        Generate fast conversational response for simple queries

        Args:
            message: User message
            user_id: User identifier
            conversation_history: Optional chat history
            max_tokens: Max tokens (default 50 for brief responses)

        Returns:
            {
                "text": "response",
                "model": "claude-haiku-4-5-20251001",
                "provider": "anthropic",
                "ai_used": "haiku",
                "tokens": {"input": X, "output": Y}
            }
        """
        try:
            logger.info(f"üèÉ [Haiku] Fast response for user {user_id}")

            # Build messages
            messages = []

            # Add conversation history if provided
            if conversation_history:
                messages.extend(conversation_history)

            # Add current message
            messages.append({
                "role": "user",
                "content": message
            })

            # Call Claude Haiku 4.5 with Prompt Caching
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=max_tokens,
                temperature=0.7,  # Conversational tone
                system=self._build_system_prompt_cached(memory_context=memory_context),  # Cached!
                messages=messages
            )

            # Extract response text
            response_text = response.content[0].text if response.content else ""

            # NOTE: Contact info removed - let AI decide naturally (already in system prompt)
            # if "+62 859 0436 9574" not in response_text and "info@balizero.com" not in response_text:
            #     response_text += "\n\nPer assistenza diretta: WhatsApp +62 859 0436 9574 o info@balizero.com"

            # Extract token usage
            tokens = {
                "input": response.usage.input_tokens,
                "output": response.usage.output_tokens
            }

            logger.info(f"‚úÖ [Haiku] Response: {len(response_text)} chars, {tokens['output']} tokens")

            return {
                "text": response_text,
                "model": self.model,
                "provider": "anthropic",
                "ai_used": "haiku",
                "tokens": tokens
            }

        except Exception as e:
            logger.error(f"‚ùå [Haiku] Error: {e}")
            raise Exception(f"Claude Haiku error: {str(e)}")


    async def conversational_with_tools(
        self,
        message: str,
        user_id: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        memory_context: Optional[str] = None,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_executor: Optional[Any] = None,
        max_tokens: int = 50,
        max_tool_iterations: int = 2  # LIMITED for speed
    ) -> Dict:
        """
        Generate fast conversational response WITH LIMITED tool use support

        Args:
            message: User message
            user_id: User identifier
            conversation_history: Optional chat history
            tools: List of Anthropic tool definitions (should be VERY LIMITED for Haiku)
            tool_executor: ToolExecutor instance for executing tools
            max_tokens: Max tokens (default 50 for brief responses)
            max_tool_iterations: Max tool use iterations (default 2, LIMITED for speed)

        Returns:
            {
                "text": "response",
                "model": "claude-haiku-4-5-20251001",
                "provider": "anthropic",
                "ai_used": "haiku",
                "tokens": {"input": X, "output": Y},
                "used_tools": bool,
                "tools_called": ["tool1", ...]
            }

        Note: Haiku tool use is LIMITED to maintain speed/cost benefits.
              Only essential, fast-executing tools should be provided.
        """
        try:
            logger.info(f"üèÉ [Haiku+Tools] Fast response for user {user_id}")
            if tools:
                logger.info(f"   Tools available: {len(tools)} (LIMITED mode)")

            # Build messages
            messages = []

            # Add conversation history if provided
            if conversation_history:
                messages.extend(conversation_history)

            # Add current message
            messages.append({
                "role": "user",
                "content": message
            })

            # Track tool usage
            tools_called = []
            total_input_tokens = 0
            total_output_tokens = 0

            # Agentic loop: LIMITED iterations for Haiku
            iteration = 0
            while iteration < max_tool_iterations:
                iteration += 1
                logger.info(f"üîÑ [Haiku+Tools] Iteration {iteration}/{max_tool_iterations}")

                # Call Claude Haiku 4.5 with Prompt Caching (with or without tools)
                api_params = {
                    "model": self.model,
                    "max_tokens": max_tokens,
                    "temperature": 0.7,
                    "system": self._build_system_prompt_cached(memory_context=memory_context),  # Cached!
                    "messages": messages
                }

                if tools:
                    api_params["tools"] = tools

                response = await self.client.messages.create(**api_params)

                # Track tokens
                total_input_tokens += response.usage.input_tokens
                total_output_tokens += response.usage.output_tokens

                # Check stop reason
                stop_reason = response.stop_reason
                logger.info(f"   Stop reason: {stop_reason}")

                # If AI wants to use tools
                if stop_reason == "tool_use" and tool_executor:
                    # Extract tool use blocks
                    tool_uses = [block for block in response.content if block.type == "tool_use"]

                    if not tool_uses:
                        logger.warning("   Stop reason is tool_use but no tool_use blocks found")
                        break

                    logger.info(f"üîß [Haiku+Tools] AI requesting {len(tool_uses)} tools")

                    # Execute tools
                    tool_results = await tool_executor.execute_tool_calls(tool_uses)

                    # Track tools called
                    for tool_use in tool_uses:
                        tool_name = tool_use.name
                        tools_called.append(tool_name)
                        logger.info(f"   ‚úÖ Executed: {tool_name}")

                    # Add assistant response with tool uses to messages
                    messages.append({
                        "role": "assistant",
                        "content": response.content
                    })

                    # Add tool results to messages
                    messages.append({
                        "role": "user",
                        "content": tool_results
                    })

                    # Continue loop to get final response
                    continue

                # If AI provided final text response
                elif stop_reason in ["end_turn", "stop_sequence"]:
                    # Extract text from response
                    response_text = ""
                    for block in response.content:
                        if hasattr(block, 'text'):
                            response_text += block.text

                    # NOTE: Contact info removed - let AI decide naturally
                    # if "+62 859 0436 9574" not in response_text and "info@balizero.com" not in response_text:
                    #     response_text += "\n\nPer assistenza diretta: WhatsApp +62 859 0436 9574 o info@balizero.com"

                    logger.info(f"‚úÖ [Haiku+Tools] Response: {len(response_text)} chars, {len(tools_called)} tools used")

                    return {
                        "text": response_text,
                        "model": self.model,
                        "provider": "anthropic",
                        "ai_used": "haiku",
                        "tokens": {
                            "input": total_input_tokens,
                            "output": total_output_tokens
                        },
                        "used_tools": len(tools_called) > 0,
                        "tools_called": tools_called
                    }

                else:
                    logger.warning(f"   Unexpected stop reason: {stop_reason}")
                    break

            # If we hit max iterations
            logger.warning(f"‚ö†Ô∏è [Haiku+Tools] Hit max iterations ({max_tool_iterations})")

            # Try to extract any text from last response
            response_text = ""
            for block in response.content:
                if hasattr(block, 'text'):
                    response_text += block.text

            if not response_text:
                response_text = "Ciao! Come posso aiutarti oggi? üòä"  # Removed auto WhatsApp

            return {
                "text": response_text,
                "model": self.model,
                "provider": "anthropic",
                "ai_used": "haiku",
                "tokens": {
                    "input": total_input_tokens,
                    "output": total_output_tokens
                },
                "used_tools": len(tools_called) > 0,
                "tools_called": tools_called
            }

        except Exception as e:
            logger.error(f"‚ùå [Haiku+Tools] Error: {e}")
            raise Exception(f"Claude Haiku tool use error: {str(e)}")


    async def stream(
        self,
        message: str,
        user_id: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        memory_context: Optional[str] = None,
        max_tokens: int = 150
    ):
        """
        Stream conversational response token by token for SSE

        Args:
            message: User message
            user_id: User identifier
            conversation_history: Optional chat history
            memory_context: Optional memory context
            max_tokens: Max tokens (default 150 for streaming)

        Yields:
            str: Text chunks as they arrive
        """
        try:
            logger.info(f"üèÉ [Haiku Stream] Starting stream for user {user_id}")

            # Build messages
            messages = []

            # Add conversation history if provided
            if conversation_history:
                messages.extend(conversation_history)

            # Add current message
            messages.append({
                "role": "user",
                "content": message
            })

            # Stream response from Claude Haiku 4.5 with Prompt Caching
            async with self.client.messages.stream(
                model=self.model,
                max_tokens=max_tokens,
                temperature=0.7,
                system=self._build_system_prompt_cached(memory_context=memory_context),  # Cached!
                messages=messages
            ) as stream:
                async for text in stream.text_stream:
                    yield text

            logger.info(f"‚úÖ [Haiku Stream] Stream completed for user {user_id}")

        except Exception as e:
            logger.error(f"‚ùå [Haiku Stream] Error: {e}")
            raise Exception(f"Claude Haiku stream error: {str(e)}")


    def is_available(self) -> bool:
        """Check if Claude Haiku is configured and available"""
        return bool(self.api_key)
