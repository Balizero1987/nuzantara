"""
Cultural RAG Service - Retrieve LLAMA-generated Indonesian cultural intelligence

This service retrieves cultural insights from ChromaDB that were generated by LLAMA FT
and injects them as context for Claude Haiku to provide culturally-aware responses.

Pattern: LLAMA generates cultural knowledge offline ‚Üí ChromaDB stores ‚Üí Claude uses at runtime
Cost: Zero (pre-generated, instant retrieval)
Latency: <5ms (ChromaDB vector search)
"""

import logging
from typing import List, Dict, Optional, Any

logger = logging.getLogger(__name__)


class CulturalRAGService:
    """
    Retrieves LLAMA-generated Indonesian cultural intelligence for Claude enrichment
    """

    def __init__(self, search_service):
        """
        Initialize CulturalRAGService

        Args:
            search_service: SearchService instance with cultural_insights collection
        """
        self.search_service = search_service
        logger.info("‚úÖ CulturalRAGService initialized")

    async def get_cultural_context(
        self,
        context_params: Dict[str, Any],
        limit: int = 2
    ) -> List[Dict[str, Any]]:
        """
        Get relevant cultural context based on conversation parameters

        Args:
            context_params: Dict with:
                - query (str): User message
                - intent (str): Intent category (greeting, casual, business_simple, etc.)
                - conversation_stage (str): "first_contact" or "ongoing"
            limit: Max cultural insights to return

        Returns:
            List of cultural insight dicts with content and metadata
        """
        try:
            query = context_params.get("query", "")
            intent = context_params.get("intent", "casual")
            conversation_stage = context_params.get("conversation_stage", "ongoing")

            # Map intent to when_to_use contexts
            intent_to_context = {
                "greeting": "first_contact",
                "casual": "casual_chat",
                "business_simple": None,  # No specific context, use semantic match
                "business_complex": None,
                "emotional_support": "casual_chat"
            }

            when_to_use = intent_to_context.get(intent)

            # Special handling for first contact
            if conversation_stage == "first_contact":
                when_to_use = "first_contact"

            # Query cultural insights from ChromaDB
            cultural_insights = await self.search_service.query_cultural_insights(
                query=query,
                when_to_use=when_to_use,
                limit=limit
            )

            logger.info(f"üå¥ Retrieved {len(cultural_insights)} cultural insights (intent: {intent}, stage: {conversation_stage})")

            return cultural_insights

        except Exception as e:
            logger.error(f"‚ùå Failed to get cultural context: {e}")
            return []

    def build_cultural_prompt_injection(self, cultural_chunks: List[Dict[str, Any]]) -> str:
        """
        Build cultural context string for injection into Claude's system prompt

        Args:
            cultural_chunks: List of cultural insight dicts from get_cultural_context

        Returns:
            Formatted cultural context string
        """
        if not cultural_chunks:
            return ""

        try:
            context_parts = [
                "## üå¥ Indonesian Cultural Intelligence (from ZANTARA's soul)",
                ""
            ]

            for i, chunk in enumerate(cultural_chunks, 1):
                topic = chunk["metadata"].get("topic", "cultural_insight")
                topic_display = topic.replace("_", " ").title()
                content = chunk["content"]
                score = chunk.get("score", 0.0)

                # Only include high-relevance insights (score > 0.3)
                if score < 0.3:
                    continue

                context_parts.append(f"**{i}. {topic_display}** (relevance: {score:.2f})")
                context_parts.append(content)
                context_parts.append("")

            context_parts.append("**How to use this intelligence:**")
            context_parts.append("- Infuse your response with this cultural awareness naturally")
            context_parts.append("- Don't quote these insights directly - internalize them")
            context_parts.append("- Show cultural sensitivity in your tone and word choice")
            context_parts.append("- Remember: you're not just informing, you're building trust")

            cultural_context = "\n".join(context_parts)

            logger.info(f"üìù Built cultural injection: {len(cultural_context)} chars from {len(cultural_chunks)} chunks")
            return cultural_context

        except Exception as e:
            logger.error(f"‚ùå Failed to build cultural injection: {e}")
            return ""

    async def get_cultural_topics_coverage(self) -> Dict[str, int]:
        """
        Get statistics on what cultural topics are available in ChromaDB

        Returns:
            Dict mapping topic names to count
        """
        try:
            # This would require ChromaDB collection inspection
            # For now, return expected topics
            expected_topics = [
                "indonesian_greetings",
                "bureaucracy_patience",
                "face_saving_culture",
                "tri_hita_karana",
                "hierarchy_respect",
                "meeting_etiquette",
                "ramadan_business",
                "relationship_capital",
                "flexibility_expectations",
                "language_barrier_navigation"
            ]

            return {topic: 1 for topic in expected_topics}

        except Exception as e:
            logger.error(f"‚ùå Failed to get cultural topics coverage: {e}")
            return {}


# Test function
async def test_cultural_rag():
    """Test CulturalRAGService"""
    from services.search_service import SearchService

    # Initialize
    search_service = SearchService()
    cultural_rag = CulturalRAGService(search_service)

    # Test queries
    test_cases = [
        {
            "query": "ciao",
            "intent": "greeting",
            "conversation_stage": "first_contact"
        },
        {
            "query": "aku malu bertanya tentang visa",
            "intent": "casual",
            "conversation_stage": "ongoing"
        },
        {
            "query": "why is Indonesian bureaucracy so slow?",
            "intent": "business_simple",
            "conversation_stage": "ongoing"
        }
    ]

    for i, test in enumerate(test_cases, 1):
        print(f"\n{'=' * 60}")
        print(f"TEST {i}: {test['query']}")
        print(f"Intent: {test['intent']}, Stage: {test['conversation_stage']}")
        print(f"{'=' * 60}")

        # Get cultural context
        cultural_chunks = await cultural_rag.get_cultural_context(test, limit=2)

        if cultural_chunks:
            print(f"\n‚úÖ Found {len(cultural_chunks)} cultural insights:")
            for chunk in cultural_chunks:
                topic = chunk["metadata"].get("topic", "unknown")
                score = chunk.get("score", 0.0)
                print(f"\n   Topic: {topic} (score: {score:.2f})")
                print(f"   Content: {chunk['content'][:150]}...")

            # Build injection
            injection = cultural_rag.build_cultural_prompt_injection(cultural_chunks)
            print(f"\nüìù Cultural Injection ({len(injection)} chars):")
            print(injection[:300] + "...\n")
        else:
            print("\n‚ùå No cultural insights found")

    # Coverage
    print(f"\n{'=' * 60}")
    print("CULTURAL TOPICS COVERAGE")
    print(f"{'=' * 60}")
    coverage = await cultural_rag.get_cultural_topics_coverage()
    for topic, count in coverage.items():
        print(f"   {topic}: {count} insight(s)")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_cultural_rag())
