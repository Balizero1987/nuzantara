"""
Golden Answer Service - Firestore Version
Fast lookup of pre-generated FAQ answers using Firestore

Provides sub-100ms lookup of cached answers for frequent queries.
Integrated into Sonnet workflow BEFORE RAG search.

Flow:
1. User query comes in
2. Check golden_answers collection in Firestore (10-20ms lookup)
3. If match found ‚Üí return cached answer immediately
4. If no match ‚Üí proceed to normal RAG + Sonnet generation

This provides 250x speedup for ~50-60% of queries.
"""

import logging
from typing import Optional, Dict, List
from datetime import datetime
import hashlib
from google.cloud import firestore
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

logger = logging.getLogger(__name__)


class GoldenAnswerServiceFirestore:
    """
    Fast lookup and retrieval of pre-generated golden answers using Firestore
    """

    def __init__(self, project_id: str):
        """
        Initialize service

        Args:
            project_id: Google Cloud project ID
        """
        self.project_id = project_id
        self.db: Optional[firestore.AsyncClient] = None
        self.model: Optional[SentenceTransformer] = None
        self.similarity_threshold = 0.80  # 80% similarity required

    async def connect(self):
        """Initialize Firestore client"""
        try:
            self.db = firestore.AsyncClient(project=self.project_id)
            logger.info("‚úÖ GoldenAnswerServiceFirestore connected to Firestore")
        except Exception as e:
            logger.error(f"‚ùå Firestore connection failed: {e}")
            raise

    async def close(self):
        """Close Firestore client"""
        if self.db:
            self.db.close()
            logger.info("GoldenAnswerServiceFirestore connection closed")

    def _load_model(self):
        """Lazy load embedding model"""
        if self.model is None:
            logger.info("Loading embedding model for similarity matching...")
            self.model = SentenceTransformer('all-MiniLM-L6-v2')

    async def lookup_golden_answer(
        self,
        query: str,
        user_id: Optional[str] = None
    ) -> Optional[Dict]:
        """
        Lookup golden answer for user query

        Args:
            query: User query text
            user_id: User ID (for analytics)

        Returns:
            Dict with answer, sources, confidence if found, else None
        """
        if not self.db:
            await self.connect()

        try:
            # Generate query hash for exact match
            query_hash = hashlib.md5(query.lower().strip().encode('utf-8')).hexdigest()

            # Step 1: Try exact match in query_hash index
            query_ref = self.db.collection('golden_answers_queries').document(query_hash)
            query_doc = await query_ref.get()

            if query_doc.exists:
                query_data = query_doc.to_dict()
                cluster_id = query_data.get('cluster_id')

                # Fetch golden answer
                answer_ref = self.db.collection('golden_answers').document(cluster_id)
                answer_doc = await answer_ref.get()

                if answer_doc.exists:
                    answer_data = answer_doc.to_dict()
                    logger.info(f"‚úÖ Exact golden answer match: {cluster_id}")

                    # Increment usage count
                    await self._increment_usage(cluster_id)

                    return {
                        "cluster_id": cluster_id,
                        "canonical_question": answer_data.get('canonical_question'),
                        "answer": answer_data.get('answer'),
                        "sources": answer_data.get('sources', []),
                        "confidence": answer_data.get('confidence', 0.0),
                        "match_type": "exact"
                    }

            # Step 2: Try semantic similarity match
            semantic_match = await self._semantic_lookup(query)

            if semantic_match:
                logger.info(f"‚úÖ Semantic golden answer match: {semantic_match['cluster_id']} (similarity: {semantic_match['similarity']:.2f})")

                # Increment usage count
                await self._increment_usage(semantic_match['cluster_id'])

                return semantic_match

            # No match found
            logger.debug(f"‚ùå No golden answer found for: {query[:60]}...")
            return None

        except Exception as e:
            logger.error(f"‚ùå Golden answer lookup failed: {e}")
            return None

    async def _semantic_lookup(self, query: str) -> Optional[Dict]:
        """
        Find golden answer using semantic similarity

        Args:
            query: User query

        Returns:
            Best matching golden answer if similarity > threshold
        """
        if not self.db:
            return None

        try:
            # Load embedding model
            self._load_model()

            # Get top 100 most used golden answers from Firestore
            answers_ref = self.db.collection('golden_answers')
            answers_query = answers_ref.order_by('usage_count', direction=firestore.Query.DESCENDING).limit(100)

            golden_answers = []
            async for doc in answers_query.stream():
                data = doc.to_dict()
                data['cluster_id'] = doc.id
                golden_answers.append(data)

            if not golden_answers:
                return None

            # Generate embeddings
            query_embedding = self.model.encode([query])[0]
            canonical_questions = [ga["canonical_question"] for ga in golden_answers]
            canonical_embeddings = self.model.encode(canonical_questions)

            # Calculate similarities
            similarities = cosine_similarity([query_embedding], canonical_embeddings)[0]

            # Find best match above threshold
            best_idx = np.argmax(similarities)
            best_similarity = similarities[best_idx]

            if best_similarity >= self.similarity_threshold:
                best_match = golden_answers[best_idx]

                return {
                    "cluster_id": best_match["cluster_id"],
                    "canonical_question": best_match["canonical_question"],
                    "answer": best_match["answer"],
                    "sources": best_match.get("sources", []),
                    "confidence": best_match.get("confidence", 0.0),
                    "match_type": "semantic",
                    "similarity": float(best_similarity)
                }

            return None

        except Exception as e:
            logger.error(f"‚ùå Semantic lookup failed: {e}")
            return None

    async def _increment_usage(self, cluster_id: str):
        """
        Increment usage_count and update last_used_at for golden answer

        Args:
            cluster_id: Golden answer cluster ID
        """
        if not self.db:
            return

        try:
            answer_ref = self.db.collection('golden_answers').document(cluster_id)
            await answer_ref.update({
                'usage_count': firestore.Increment(1),
                'last_used_at': firestore.SERVER_TIMESTAMP
            })

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to increment usage for {cluster_id}: {e}")

    async def get_golden_answer_stats(self) -> Dict:
        """
        Get statistics about golden answer usage

        Returns:
            Dict with statistics
        """
        if not self.db:
            await self.connect()

        answers_ref = self.db.collection('golden_answers')

        # Get all golden answers
        all_answers = []
        async for doc in answers_ref.stream():
            data = doc.to_dict()
            all_answers.append(data)

        if not all_answers:
            return {
                "total_golden_answers": 0,
                "total_hits": 0,
                "avg_confidence": 0.0,
                "max_usage": 0,
                "min_usage": 0,
                "top_10": []
            }

        # Calculate stats
        total = len(all_answers)
        total_hits = sum(a.get('usage_count', 0) for a in all_answers)
        avg_confidence = sum(a.get('confidence', 0.0) for a in all_answers) / total if total > 0 else 0.0
        max_usage = max((a.get('usage_count', 0) for a in all_answers), default=0)
        min_usage = min((a.get('usage_count', 0) for a in all_answers), default=0)

        # Get top 10
        sorted_answers = sorted(all_answers, key=lambda x: x.get('usage_count', 0), reverse=True)[:10]

        return {
            "total_golden_answers": total,
            "total_hits": total_hits,
            "avg_confidence": avg_confidence,
            "max_usage": max_usage,
            "min_usage": min_usage,
            "top_10": [
                {
                    "canonical_question": row.get("canonical_question"),
                    "usage_count": row.get("usage_count", 0),
                    "last_used": row.get("last_used_at").isoformat() if row.get("last_used_at") else None
                }
                for row in sorted_answers
            ]
        }


# Convenience function for testing
async def test_service():
    """Test golden answer service"""
    import os

    project_id = os.getenv("FIREBASE_PROJECT_ID")
    if not project_id:
        print("‚ùå FIREBASE_PROJECT_ID not set")
        return

    service = GoldenAnswerServiceFirestore(project_id)

    try:
        await service.connect()

        print("\nüîç TESTING GOLDEN ANSWER LOOKUP (Firestore)")
        print("=" * 60)

        # Test query
        test_query = "How to get KITAS in Indonesia?"

        print(f"\nQuery: {test_query}")
        result = await service.lookup_golden_answer(test_query)

        if result:
            print(f"\n‚úÖ MATCH FOUND!")
            print(f"Match type: {result['match_type']}")
            print(f"Cluster ID: {result['cluster_id']}")
            print(f"Canonical: {result['canonical_question']}")
            print(f"Confidence: {result['confidence']}")
            print(f"\nAnswer:")
            print(result['answer'][:300] + "...")
            print(f"\nSources: {len(result.get('sources', []))}")
        else:
            print("\n‚ùå No match found")

        # Get stats
        print("\nüìä GOLDEN ANSWER STATISTICS")
        print("=" * 60)
        stats = await service.get_golden_answer_stats()
        print(f"Total golden answers: {stats['total_golden_answers']}")
        print(f"Total cache hits: {stats['total_hits']}")
        print(f"Average confidence: {stats['avg_confidence']:.2f}")

    finally:
        await service.close()


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_service())