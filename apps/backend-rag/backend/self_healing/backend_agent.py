"""
ðŸ¤– ZANTARA Backend Self-Healing Agent

Autonomous agent that monitors backend service health and auto-fixes issues
Runs continuously on each Fly.io service (RAG, Memory, etc.)

Features:
- Health checks (API, DB, Redis, Qdrant)
- Auto-restart on failures
- Memory leak detection
- Database connection pool management
- API endpoint monitoring
- Reports to Central Orchestrator
"""

import asyncio
import logging
import sys
import time
import traceback
from dataclasses import asdict, dataclass
from typing import Any

import httpx
import psutil
import redis

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="ðŸ¤– [Backend Agent] %(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class HealthMetrics:
    """Health metrics for the service"""

    timestamp: float
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    api_healthy: bool
    db_healthy: bool
    cache_healthy: bool
    error_count: int
    fix_count: int
    uptime: float


@dataclass
class ErrorReport:
    """Error report to send to orchestrator"""

    agent: str
    service: str
    error_type: str
    severity: str  # low, medium, high, critical
    message: str
    timestamp: float
    context: dict[str, Any]
    fix_attempted: bool
    fix_success: bool


class BackendSelfHealingAgent:
    """Self-healing agent for backend services"""

    def __init__(
        self,
        service_name: str,
        orchestrator_url: str = "https://nuzantara-orchestrator.fly.dev",
        check_interval: int = 30,
        auto_fix_enabled: bool = True,
    ):
        self.service_name = service_name
        self.orchestrator_url = orchestrator_url
        self.check_interval = check_interval
        self.auto_fix_enabled = auto_fix_enabled

        # Metrics
        self.start_time = time.time()
        self.error_count = 0
        self.fix_count = 0
        self.error_history: list[ErrorReport] = []
        self.fix_history: list[dict] = []

        # Health check URLs
        self.health_urls = {
            "api": "http://localhost:8000/health",
            "db": None,  # Configured per service
            "cache": None,  # Configured per service
        }

        # External clients
        self.http_client = httpx.AsyncClient(timeout=10.0)
        self.redis_client = None

        logger.info(f"Initializing agent for service: {service_name}")

    async def start(self):
        """Start the agent"""
        logger.info("ðŸš€ Starting self-healing agent...")

        # Report startup to orchestrator
        from app.core.config import settings
        await self.report_to_orchestrator(
            {
                "type": "agent_startup",
                "severity": "low",
                "data": {
                    "service": self.service_name,
                    "hostname": settings.hostname or "unknown",
                    "fly_region": settings.fly_region or "unknown",
                },
            }
        )

        # Start monitoring loop
        await self.monitoring_loop()

    async def monitoring_loop(self):
        """Main monitoring loop"""
        while True:
            try:
                # Perform health check
                await self.perform_health_check()

                # Check for issues
                issues = await self.detect_issues()

                # Attempt auto-fix if enabled
                if self.auto_fix_enabled and issues:
                    await self.attempt_auto_fix(issues)

                # Wait before next check
                await asyncio.sleep(self.check_interval)

            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(5)  # Brief pause before retry

    async def perform_health_check(self) -> HealthMetrics:
        """Perform comprehensive health check"""
        try:
            # System metrics
            cpu = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory().percent
            disk = psutil.disk_usage("/").percent

            # API health
            api_healthy = await self.check_api_health()

            # DB health
            db_healthy = await self.check_db_health()

            # Cache health
            cache_healthy = await self.check_cache_health()

            metrics = HealthMetrics(
                timestamp=time.time(),
                cpu_usage=cpu,
                memory_usage=memory,
                disk_usage=disk,
                api_healthy=api_healthy,
                db_healthy=db_healthy,
                cache_healthy=cache_healthy,
                error_count=self.error_count,
                fix_count=self.fix_count,
                uptime=time.time() - self.start_time,
            )

            # Log metrics
            logger.info(
                f"Health: CPU={cpu:.1f}% MEM={memory:.1f}% "
                f"API={'âœ…' if api_healthy else 'âŒ'} "
                f"DB={'âœ…' if db_healthy else 'âŒ'} "
                f"Cache={'âœ…' if cache_healthy else 'âŒ'}"
            )

            # Report to orchestrator
            await self.report_to_orchestrator(
                {"type": "health_check", "severity": "low", "data": asdict(metrics)}
            )

            return metrics

        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return None

    async def check_api_health(self) -> bool:
        """Check if API is responding"""
        try:
            response = await self.http_client.get(self.health_urls["api"], timeout=5.0)
            return response.status_code == 200
        except Exception as e:
            logger.warning(f"API health check failed: {e}")
            return False

    async def check_db_health(self) -> bool:
        """Check if database is accessible"""
        # Implementation depends on DB type (PostgreSQL, Qdrant, etc.)
        # Placeholder for now
        return True

    async def check_cache_health(self) -> bool:
        """Check if Redis cache is accessible"""
        try:
            if not self.redis_client:
                from app.core.config import settings
                redis_url = settings.redis_url
                if redis_url:
                    self.redis_client = redis.from_url(redis_url)

            if self.redis_client:
                self.redis_client.ping()
                return True

            return True  # No cache configured

        except Exception as e:
            logger.warning(f"Cache health check failed: {e}")
            return False

    async def detect_issues(self) -> list[dict]:
        """Detect current issues"""
        issues = []

        # Check high CPU usage
        cpu = psutil.cpu_percent(interval=1)
        if cpu > 90:
            issues.append(
                {
                    "type": "high_cpu",
                    "severity": "high",
                    "value": cpu,
                    "message": f"CPU usage at {cpu:.1f}%",
                }
            )

        # Check high memory usage
        memory = psutil.virtual_memory().percent
        if memory > 90:
            issues.append(
                {
                    "type": "high_memory",
                    "severity": "critical",
                    "value": memory,
                    "message": f"Memory usage at {memory:.1f}%",
                }
            )

        # Check disk space
        disk = psutil.disk_usage("/").percent
        if disk > 90:
            issues.append(
                {
                    "type": "high_disk",
                    "severity": "high",
                    "value": disk,
                    "message": f"Disk usage at {disk:.1f}%",
                }
            )

        # Check API health
        if not await self.check_api_health():
            issues.append(
                {"type": "api_down", "severity": "critical", "message": "API health check failing"}
            )

        # Check DB health
        if not await self.check_db_health():
            issues.append(
                {
                    "type": "db_down",
                    "severity": "critical",
                    "message": "Database health check failing",
                }
            )

        # Check cache health
        if not await self.check_cache_health():
            issues.append(
                {
                    "type": "cache_down",
                    "severity": "medium",
                    "message": "Cache health check failing",
                }
            )

        if issues:
            logger.warning(f"Detected {len(issues)} issue(s): {[i['type'] for i in issues]}")

        return issues

    async def attempt_auto_fix(self, issues: list[dict]):
        """Attempt to auto-fix detected issues"""
        for issue in issues:
            logger.info(f"ðŸ”§ Attempting auto-fix for: {issue['type']}")

            fix_success = False
            fix_strategy = None

            try:
                if issue["type"] == "high_memory":
                    # Trigger garbage collection
                    import gc

                    gc.collect()
                    fix_strategy = "garbage_collection"
                    fix_success = True

                elif issue["type"] == "high_cpu":
                    # Log warning, may need manual intervention
                    fix_strategy = "monitor_only"
                    fix_success = False

                elif issue["type"] == "api_down":
                    # Try to restart API (if we have the capability)
                    fix_strategy = "restart_api"
                    fix_success = await self.restart_service()

                elif issue["type"] == "db_down":
                    # Try to reconnect
                    fix_strategy = "reconnect_db"
                    fix_success = await self.reconnect_database()

                elif issue["type"] == "cache_down":
                    # Try to reconnect
                    fix_strategy = "reconnect_cache"
                    fix_success = await self.reconnect_cache()

                # Track fix attempt
                self.fix_history.append(
                    {
                        "timestamp": time.time(),
                        "issue_type": issue["type"],
                        "strategy": fix_strategy,
                        "success": fix_success,
                    }
                )

                if fix_success:
                    self.fix_count += 1
                    logger.info(f"âœ… Auto-fix successful for {issue['type']}")
                else:
                    self.error_count += 1
                    logger.warning(f"âŒ Auto-fix failed for {issue['type']}")

                    # Escalate to orchestrator
                    await self.report_to_orchestrator(
                        {
                            "type": "auto_fix_failed",
                            "severity": issue["severity"],
                            "data": {"issue": issue, "fix_strategy": fix_strategy},
                        }
                    )

            except Exception as e:
                logger.error(f"Error during auto-fix: {e}")
                self.error_count += 1

                # Report error
                await self.report_to_orchestrator(
                    {
                        "type": "auto_fix_error",
                        "severity": "high",
                        "data": {
                            "issue": issue,
                            "error": str(e),
                            "traceback": traceback.format_exc(),
                        },
                    }
                )

    async def restart_service(self) -> bool:
        """Restart the service (if possible)"""
        logger.info("Attempting service restart...")
        # In Fly.io, we can trigger a restart by exiting with non-zero
        # Supervisor will restart the process
        # For now, just return False (manual restart needed)
        return False

    async def reconnect_database(self) -> bool:
        """Reconnect to database"""
        logger.info("Attempting database reconnection...")
        # Implementation depends on DB type
        # Placeholder for now
        return False

    async def reconnect_cache(self) -> bool:
        """Reconnect to cache"""
        logger.info("Attempting cache reconnection...")
        try:
            from app.core.config import settings
            redis_url = settings.redis_url
            if redis_url:
                self.redis_client = redis.from_url(redis_url)
                self.redis_client.ping()
                return True
        except Exception as e:
            logger.error(f"Cache reconnection failed: {e}")

        return False

    async def report_to_orchestrator(self, event: dict):
        """Report event to Central Orchestrator"""
        try:
            payload = {
                "agent": "backend",
                "service": self.service_name,
                "hostname": settings.hostname or "unknown",
                "region": settings.fly_region or "unknown",
                "event": event,
                "timestamp": time.time(),
            }

            await self.http_client.post(
                f"{self.orchestrator_url}/api/report", json=payload, timeout=5.0
            )

        except Exception as e:
            # Silently fail - don't disrupt service
            logger.debug(f"Failed to report to orchestrator: {e}")

    def get_status(self) -> dict:
        """Get agent status"""
        return {
            "service": self.service_name,
            "uptime": time.time() - self.start_time,
            "error_count": self.error_count,
            "fix_count": self.fix_count,
            "fix_success_rate": f"{(self.fix_count / max(self.error_count, 1) * 100):.1f}%",
            "recent_errors": self.error_history[-10:],
            "recent_fixes": self.fix_history[-10:],
        }


# Auto-start agent if run directly
if __name__ == "__main__":
    from app.core.config import settings
    service_name = settings.service_name
    agent = BackendSelfHealingAgent(service_name=service_name)

    try:
        asyncio.run(agent.start())
    except KeyboardInterrupt:
        logger.info("Agent stopped by user")
    except Exception as e:
        logger.error(f"Agent crashed: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)
