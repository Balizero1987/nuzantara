app = "nuzantara-ai-engine"
primary_region = "sin"

[build]
  dockerfile = "Dockerfile"

# Persist the GGUF model and Ollama data
[mounts]
  source = "ai_data"
  destination = "/data"

# Expose the API via HTTP
[http_service]
  internal_port = 11434
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1

# CPU-Only Performance Configuration
[[vm]]
  size = "performance-4x"
  cpu_kind = "performance"
  cpus = 4
  memory_mb = 8192

