/**
 * ðŸš€ ZANTARA v3 Î© Performance Cache Layer
 * 
 * CRITICAL OPTIMIZATION: Reduce 30s response time to <2s
 * 
 * Features:
 * - Domain-specific TTL strategies
 * - Parallel query execution
 * - Request deduplication
 * - Intelligent cache warming
 * - Automatic fallback on cache miss
 * 
 * Performance Targets:
 * - Quick mode: <500ms (90th percentile)
 * - Detailed mode: <2s (90th percentile)
 * - Comprehensive mode: <5s (95th percentile)
 * 
 * @author Claude Sonnet 4.5
 * @date 2025-11-02
 */

import { getEnhancedCache, EnhancedRedisCache } from './performance/enhanced-redis-cache.js';
import logger from './logger.js';
import crypto from 'crypto';

// Domain-specific cache TTL configurations (in seconds)
export const CACHE_TTL_CONFIG = {
  kbli: 3600,           // 1 hour - static data
  pricing: 14400,       // 4 hours - business-critical but stable
  team: 1800,           // 30 minutes - changes often
  legal: 21600,         // 6 hours - stable regulations
  immigration: 21600,   // 6 hours - stable regulations
  tax: 21600,           // 6 hours - stable regulations
  property: 21600,      // 6 hours - stable regulations
  business: 7200,       // 2 hours - business setup info
  memory: 900,          // 15 minutes - user-generated content
  collective: 900       // 15 minutes - collective intelligence
} as const;

type CacheDomain = keyof typeof CACHE_TTL_CONFIG;

interface V3QueryParams {
  query: string;
  domain?: string;
  mode?: 'quick' | 'detailed' | 'comprehensive';
  include_sources?: boolean;
  [key: string]: any;
}

interface CacheMetrics {
  totalQueries: number;
  cacheHits: number;
  cacheMisses: number;
  averageResponseTime: number;
  domainMetrics: Record<string, {
    queries: number;
    hits: number;
    avgTime: number;
  }>;
}

class V3PerformanceCache {
  private cache: EnhancedRedisCache;
  private metrics: CacheMetrics;
  private pendingRequests: Map<string, Promise<any>> = new Map();
  
  constructor() {
    this.cache = getEnhancedCache({
      l1Ttl: 60,           // 1 minute L1 (in-memory)
      l2Ttl: 3600,         // 1 hour L2 (Redis)
      maxL1Size: 2000,     // Increased for v3 queries
      enableCompression: true,
      enableWarming: true,
      enableStats: true
    });
    
    this.metrics = {
      totalQueries: 0,
      cacheHits: 0,
      cacheMisses: 0,
      averageResponseTime: 0,
      domainMetrics: {}
    };
  }
  
  /**
   * Initialize cache system
   */
  async initialize(): Promise<void> {
    try {
      await this.cache.initialize();
      logger.info('âœ… V3 Performance Cache initialized');
      
      // Warm cache with common queries
      await this.warmCommonQueries();
    } catch (error: any) {
      logger.error('Failed to initialize V3 Performance Cache:', error);
    }
  }
  
  /**
   * Generate cache key for query
   */
  private generateCacheKey(params: V3QueryParams, prefix: string = 'v3'): string {
    const normalized = {
      query: params.query?.toLowerCase().trim(),
      domain: params.domain || 'all',
      mode: params.mode || 'quick',
      include_sources: params.include_sources ?? true
    };
    
    const hash = crypto
      .createHash('sha256')
      .update(JSON.stringify(normalized))
      .digest('hex')
      .substring(0, 16);
    
    return `${prefix}:${normalized.domain}:${hash}`;
  }
  
  /**
   * Get cached query result with request deduplication
   */
  async getCached<T>(
    params: V3QueryParams,
    executor: () => Promise<T>,
    domain: CacheDomain = 'kbli'
  ): Promise<T> {
    const startTime = Date.now();
    this.metrics.totalQueries++;
    
    const cacheKey = this.generateCacheKey(params);
    
    // Request deduplication: check if same query is already in flight
    const pending = this.pendingRequests.get(cacheKey);
    if (pending) {
      logger.debug(`Deduplicating request: ${cacheKey}`);
      return pending as Promise<T>;
    }
    
    try {
      // Try cache first
      const cached = await this.cache.get<T>(cacheKey);
      if (cached !== null) {
        this.metrics.cacheHits++;
        this.updateDomainMetrics(domain, true, Date.now() - startTime);
        logger.debug(`Cache HIT: ${cacheKey} (${Date.now() - startTime}ms)`);
        return cached;
      }
      
      // Cache miss - execute query
      this.metrics.cacheMisses++;
      logger.debug(`Cache MISS: ${cacheKey}`);
      
      // Create promise and track it
      const promise = executor();
      this.pendingRequests.set(cacheKey, promise);
      
      try {
        const result = await promise;
        
        // Cache the result with domain-specific TTL
        const ttl = CACHE_TTL_CONFIG[domain];
        await this.cache.set(cacheKey, result, ttl, [domain, params.mode || 'quick']);
        
        this.updateDomainMetrics(domain, false, Date.now() - startTime);
        logger.debug(`Cached result: ${cacheKey} (TTL: ${ttl}s, Time: ${Date.now() - startTime}ms)`);
        
        return result;
      } finally {
        // Clean up pending request tracking
        this.pendingRequests.delete(cacheKey);
      }
    } catch (error: any) {
      logger.error(`Cache error for ${cacheKey}:`, error);
      // On error, execute without cache
      return executor();
    }
  }
  
  /**
   * Execute multiple domain queries in parallel
   */
  async executeParallel<T>(
    queries: Array<{
      domain: CacheDomain;
      params: V3QueryParams;
      executor: () => Promise<T>;
    }>
  ): Promise<Array<{ domain: CacheDomain; result: T | null; error?: Error }>> {
    const startTime = Date.now();
    
    logger.info(`ðŸš€ Executing ${queries.length} domain queries in parallel`);
    
    const results = await Promise.allSettled(
      queries.map(async ({ domain, params, executor }) => {
        try {
          const result = await this.getCached(params, executor, domain);
          return { domain, result };
        } catch (error: any) {
          logger.error(`Domain query error (${domain}):`, error);
          return { domain, result: null, error };
        }
      })
    );
    
    const processed = results.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        return {
          domain: queries[index].domain,
          result: null,
          error: result.reason
        };
      }
    });
    
    const elapsed = Date.now() - startTime;
    logger.info(`âœ… Parallel execution complete: ${elapsed}ms (${queries.length} queries)`);
    
    return processed;
  }
  
  /**
   * Invalidate cache by domain
   */
  async invalidateDomain(domain: CacheDomain): Promise<number> {
    try {
      const count = await this.cache.invalidateTag(domain);
      logger.info(`Invalidated ${count} cache entries for domain: ${domain}`);
      return count;
    } catch (error: any) {
      logger.error(`Failed to invalidate domain ${domain}:`, error);
      return 0;
    }
  }
  
  /**
   * Invalidate specific query
   */
  async invalidateQuery(params: V3QueryParams): Promise<void> {
    try {
      const cacheKey = this.generateCacheKey(params);
      await this.cache.del(cacheKey);
      logger.debug(`Invalidated query: ${cacheKey}`);
    } catch (error: any) {
      logger.error('Failed to invalidate query:', error);
    }
  }
  
  /**
   * Warm cache with common queries
   */
  private async warmCommonQueries(): Promise<void> {
    // Common KBLI queries
    const commonQueries = [
      'restaurant',
      'hotel',
      'cafe',
      'accommodation',
      'retail',
      'services'
    ];
    
    logger.info('Warming cache with common queries...');
    
    // Pre-generate cache keys for warming
    const keys = commonQueries.map(query => 
      this.generateCacheKey({ query, domain: 'kbli', mode: 'quick' })
    );
    
    // Note: Actual warming happens lazily when queries are executed
    logger.info(`Prepared ${keys.length} cache keys for warming`);
  }
  
  /**
   * Update domain-specific metrics
   */
  private updateDomainMetrics(domain: string, hit: boolean, responseTime: number): void {
    if (!this.metrics.domainMetrics[domain]) {
      this.metrics.domainMetrics[domain] = {
        queries: 0,
        hits: 0,
        avgTime: 0
      };
    }
    
    const domainMetrics = this.metrics.domainMetrics[domain];
    domainMetrics.queries++;
    if (hit) domainMetrics.hits++;
    
    // Update moving average
    const alpha = 0.2;
    domainMetrics.avgTime = alpha * responseTime + (1 - alpha) * domainMetrics.avgTime;
    
    // Update overall average
    this.metrics.averageResponseTime = 
      alpha * responseTime + (1 - alpha) * this.metrics.averageResponseTime;
  }
  
  /**
   * Get performance metrics
   */
  getMetrics(): CacheMetrics & { cacheStats: any; hitRate: number } {
    const hitRate = this.metrics.totalQueries > 0
      ? (this.metrics.cacheHits / this.metrics.totalQueries) * 100
      : 0;
    
    return {
      ...this.metrics,
      cacheStats: this.cache.getStats(),
      hitRate: parseFloat(hitRate.toFixed(2))
    };
  }
  
  /**
   * Reset metrics
   */
  resetMetrics(): void {
    this.metrics = {
      totalQueries: 0,
      cacheHits: 0,
      cacheMisses: 0,
      averageResponseTime: 0,
      domainMetrics: {}
    };
    this.cache.resetStats();
  }
  
  /**
   * Shutdown cache
   */
  async shutdown(): Promise<void> {
    await this.cache.shutdown();
    logger.info('V3 Performance Cache shut down');
  }
}

// Singleton instance
let v3CacheInstance: V3PerformanceCache | null = null;

/**
 * Get or create V3 cache instance
 */
export function getV3Cache(): V3PerformanceCache {
  if (!v3CacheInstance) {
    v3CacheInstance = new V3PerformanceCache();
  }
  return v3CacheInstance;
}

/**
 * Initialize V3 cache
 */
export async function initializeV3Cache(): Promise<V3PerformanceCache> {
  const cache = getV3Cache();
  await cache.initialize();
  return cache;
}

export { V3PerformanceCache };
export type { V3QueryParams, CacheMetrics, CacheDomain };
