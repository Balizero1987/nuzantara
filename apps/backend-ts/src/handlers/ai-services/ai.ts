/**
 * ZANTARA-ONLY AI Service
 * Simplified AI routing with only ZANTARA/LLAMA support
 */

import logger from '../../services/logger.js';
import { ok } from '../../utils/response.js';
import { zantaraChat } from './zantara-llama.js';

// Team member recognition database
const TEAM_RECOGNITION: Record<
  string,
  { name: string; role: string; department: string; language: string; personalizedResponse: string }
> = {
  zero: {
    name: 'Zero',
    role: 'AI Bridge/Tech Lead',
    department: 'technology',
    language: 'Italian',
    personalizedResponse:
      'Ciao Zero! Bentornato. Come capo del team tech, hai accesso completo a tutti i sistemi ZANTARA e Bali Zero.',
  },
  zainal: {
    name: 'Zainal Abidin',
    role: 'CEO',
    department: 'management',
    language: 'Indonesian',
    personalizedResponse:
      'Selamat datang kembali Zainal! Sebagai CEO, Anda memiliki akses penuh ke semua sistem Bali Zero dan ZANTARA.',
  },
  antonello: {
    name: 'Antonello Siano',
    role: 'Founder',
    department: 'technology',
    language: 'Italian',
    personalizedResponse:
      'Ciao Antonello! Bentornato. Come fondatore di Bali Zero, hai accesso completo a tutti i sistemi.',
  },
};

// Check for identity recognition
function checkIdentityRecognition(prompt: string, _sessionId: string): string | null {
  const text = prompt.toLowerCase();

  for (const [, member] of Object.entries(TEAM_RECOGNITION)) {
    // Build comprehensive alias list: full name, name parts, role, department, and key
    const nameParts = member.name.toLowerCase().split(/\s+/);
    const aliases = [
      member.name.toLowerCase(), // Full name: "antonello siano"
      ...nameParts, // Name parts: ["antonello", "siano"]
      member.role.toLowerCase(), // Role: "founder"
      member.department.toLowerCase(), // Department: "technology"
    ];

    // Check if any alias matches (as substring or exact match)
    if (
      aliases.some((alias) => {
        // Match if alias is contained in text OR text contains the alias as a word
        return text.includes(alias) || new RegExp(`\\b${alias}\\b`, 'i').test(text);
      })
    ) {
      logger.info(`‚úÖ [ZANTARA] Identity recognized: ${member.name} (${member.role})`);
      return member.personalizedResponse;
    }
  }
  return null;
}

// Simplified ZANTARA context - removed unused function

// ZANTARA-ONLY AI Chat
export async function aiChat(params: any) {
  const { provider: _provider = 'zantara' } = params || {};

  logger.info('üéØ [AI Router] ZANTARA-ONLY mode - using only ZANTARA/LLAMA');

  try {
    // Check for identity recognition FIRST
    const identityResponse = checkIdentityRecognition(
      params.prompt || params.message,
      params.sessionId || 'default'
    );
    if (identityResponse) {
      logger.info(`‚úÖ [ZANTARA] Identity recognized - returning personalized response`);
      return ok({ response: identityResponse, recognized: true, ts: Date.now() });
    }

    // Use ZANTARA for all queries with mode support
    const zantaraResult = await zantaraChat({
      message: params.prompt || params.message,
      mode: params.mode || 'santai', // Default to Santai mode
      user_email: params.user_email, // CRITICAL: Pass user_email for identification
      ...params,
    });

    // Normalize response format: zantaraChat returns 'answer', but tests expect 'response'
    if (zantaraResult.ok && zantaraResult.data) {
      const data = zantaraResult.data as any;
      return ok({
        response: data.answer || data.response || '',
        answer: data.answer || data.response || '', // Keep for backward compatibility
        model: data.model || 'zantara-llama',
        provider: data.provider || 'rag-backend',
        tokens: data.tokens || 0,
        usage: data.usage || {},
        mode: data.mode || params.mode || 'santai',
        recognized: false, // Not an identity match
        ts: Date.now(),
      });
    }

    return zantaraResult;
  } catch (error: any) {
    logger.error('‚ùå ZANTARA error:', error);

    // Graceful fallback response instead of throwing error
    return ok({
      response: `Ciao! Sono ZANTARA, l'assistente AI di Bali Zero. Attualmente il mio modello personalizzato non √® disponibile, ma posso comunque aiutarti con informazioni sui nostri servizi. Come posso esserti utile oggi?`,
      model: 'zantara-fallback',
      usage: {
        prompt_tokens: 0,
        completion_tokens: 0,
        total_tokens: 0,
      },
      recognized: false,
      ts: Date.now(),
    });
  }
}

/**
 * Get Available AI Models
 * Handler #12: getAIModelsHandler
 * Returns list of available AI models and their capabilities
 */
export async function getAIModels(_params: any) {
  try {
    logger.info('üìã Fetching available AI models');

    const models = [
      {
        id: 'zantara',
        name: 'ZANTARA',
        description: 'Specialized Bali Zero AI assistant with business knowledge',
        type: 'chat',
        status: 'active',
        capabilities: ['business-analysis', 'kbli-lookup', 'visa-guidance', 'tax-planning', 'rag-search'],
        context_window: 8192,
        max_tokens: 2048,
        latency_ms: '500-1800',
        provider: 'rag-backend',
      },
      {
        id: 'llama',
        name: 'LLAMA (Fallback)',
        description: 'Open-source general-purpose language model for basic queries',
        type: 'chat',
        status: 'active',
        capabilities: ['text-generation', 'question-answering', 'summarization'],
        context_window: 4096,
        max_tokens: 1024,
        latency_ms: '1000-3000',
        provider: 'local-ollama',
      },
    ];

    return {
      success: true,
      models,
      total_models: models.length,
      default_model: 'zantara',
      timestamp: Date.now(),
    };
  } catch (error: any) {
    logger.error('Error fetching AI models:', error);
    return {
      success: false,
      error: error.message || 'Failed to fetch models',
      models: [],
      total_models: 0,
    };
  }
}

/**
 * Generate Text Embeddings
 * Handler #13: generateEmbeddingsHandler
 * Converts text to vector embeddings for semantic search
 */
export async function generateEmbeddings(params: any) {
  const { text, model = 'all-MiniLM-L6-v2' } = params || {};

  try {
    logger.info('Generating embeddings', { text: text?.substring(0, 100) });

    // Validate input
    if (!text || typeof text !== 'string') {
      return {
        success: false,
        error: 'Text is required and must be a string',
      };
    }

    if (text.length < 1) {
      return {
        success: false,
        error: 'Text cannot be empty',
      };
    }

    if (text.length > 10000) {
      return {
        success: false,
        error: 'Text too long (max 10,000 characters)',
      };
    }

    // For now, generate mock embeddings with correct structure
    // In production, this would call OpenAI's text-embedding-3-small API
    const dimension = 384; // all-MiniLM-L6-v2 uses 384 dimensions
    const embeddingVector = Array.from({ length: dimension }, () => Math.random() - 0.5);

    logger.info('Embeddings generated successfully', { model, dimension });

    return {
      success: true,
      embeddings: [
        {
          text,
          vector: embeddingVector,
          dimension,
          model,
        },
      ],
      model,
      timestamp: Date.now(),
    };
  } catch (error: any) {
    logger.error('Embeddings generation error', error, { error: error.message });
    return {
      success: false,
      error: error.message || 'Failed to generate embeddings',
    };
  }
}

/**
 * Get Text Completions
 * Handler #14: getCompletionsHandler
 * Generates text completions using available AI models
 */
export async function getCompletions(params: any) {
  const {
    prompt,
    model = 'zantara',
    max_tokens = 256,
    temperature = 0.7,
    top_p: _top_p = 0.9,
    stop: _stop,
    frequency_penalty: _frequency_penalty = 0,
    presence_penalty: _presence_penalty = 0,
  } = params || {};

  try {
    logger.info('Getting completions', { prompt: prompt?.substring(0, 100), model });

    // Validate input
    if (!prompt || typeof prompt !== 'string') {
      return {
        success: false,
        error: 'Prompt is required and must be a string',
      };
    }

    if (prompt.length < 1) {
      return {
        success: false,
        error: 'Prompt cannot be empty',
      };
    }

    // Validate parameters
    if (temperature < 0 || temperature > 2) {
      return {
        success: false,
        error: 'Temperature must be between 0 and 2',
      };
    }

    if (max_tokens < 1 || max_tokens > 4000) {
      return {
        success: false,
        error: 'max_tokens must be between 1 and 4000',
      };
    }

    // Use ZANTARA for completions
    if (model === 'zantara') {
      const result = await zantaraChat({
        message: prompt,
        mode: 'santai',
        ...params,
      });

      if (result.ok && result.data) {
        const data = result.data as any;
        return {
          success: true,
          completion: data.answer || data.response || '',
          prompt,
          model: 'zantara-llama',
          tokens: {
            prompt_tokens: Math.ceil(prompt.length / 4),
            completion_tokens: Math.ceil((data.answer?.length || 0) / 4),
            total_tokens: Math.ceil((prompt.length + (data.answer?.length || 0)) / 4),
          },
          finish_reason: 'stop',
          timestamp: Date.now(),
        };
      }
    }

    // Fallback: generate mock completion
    const mockCompletion =
      'This is a generated completion in response to: ' + prompt.substring(0, 50) + '...';

    return {
      success: true,
      completion: mockCompletion,
      prompt,
      model: model || 'fallback',
      tokens: {
        prompt_tokens: Math.ceil(prompt.length / 4),
        completion_tokens: Math.ceil(mockCompletion.length / 4),
        total_tokens: Math.ceil((prompt.length + mockCompletion.length) / 4),
      },
      finish_reason: 'stop',
      timestamp: Date.now(),
    };
  } catch (error: any) {
    logger.error('Completions error', error, { error: error.message });
    return {
      success: false,
      error: error.message || 'Failed to generate completions',
    };
  }
}
