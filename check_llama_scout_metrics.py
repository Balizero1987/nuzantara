#!/usr/bin/env python3
"""
Check Llama Scout Metrics & Status
Direct investigation of LlamaScoutClient status
"""

import asyncio
import os
import sys
import logging
from datetime import datetime

# Add the backend-rag directory to Python path
sys.path.insert(0, '/Users/antonellosiano/Desktop/NUZANTARA-FLY/apps/backend-rag')

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_llama_scout_direct():
    """Test LlamaScoutClient directly"""
    
    print("ğŸ” LLAMA SCOUT DIRECT TEST")
    print("=" * 40)
    print(f"Timestamp: {datetime.now().isoformat()}")
    print()
    
    try:
        # Import LlamaScoutClient
        from backend.llm.llama_scout_client import LlamaScoutClient
        
        # Initialize with environment variables (same as production)
        openrouter_key = os.getenv("OPENROUTER_API_KEY_LLAMA", "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")
        anthropic_key = os.getenv("ANTHROPIC_API_KEY", "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")
        
        print(f"ğŸ”‘ OpenRouter Key: {'âœ… SET' if openrouter_key else 'âŒ MISSING'}")
        print(f"ğŸ”‘ Anthropic Key: {'âœ… SET' if anthropic_key else 'âŒ MISSING'}")
        print()
        
        # Initialize client
        client = LlamaScoutClient(
            openrouter_api_key=openrouter_key,
            anthropic_api_key=anthropic_key,
            force_haiku=False
        )
        
        print(f"ğŸ¯ Client available: {client.is_available()}")
        print(f"ğŸ¦™ Llama client: {'âœ…' if client.llama_client else 'âŒ'}")
        print(f"ğŸ”µ Haiku client: {'âœ…' if client.haiku_client else 'âŒ'}")
        print()
        
        # Test simple chat
        print("ğŸ§ª Testing simple chat...")
        result = await client.chat_async(
            messages=[{"role": "user", "content": "Hello, please identify your AI model name"}],
            max_tokens=100
        )
        
        print(f"âœ… Response: {result['text'][:100]}...")
        print(f"ğŸ¤– Model: {result['model']}")
        print(f"ğŸ¢ Provider: {result['provider']}")
        print(f"ğŸ’° Cost: ${result['cost']:.6f}")
        print(f"ğŸ”¢ Tokens: {result['tokens']}")
        print()
        
        # Get metrics
        metrics = client.get_metrics()
        print("ğŸ“Š CURRENT METRICS")
        print("-" * 20)
        for key, value in metrics.items():
            print(f"{key}: {value}")
        print()
        
        # Test conversational method (IntelligentRouter compatibility)
        print("ğŸ§ª Testing conversational method...")
        conv_result = await client.conversational(
            message="Quick test - what's your model?",
            user_id="test_user"
        )
        
        print(f"âœ… Conversational response: {conv_result['text'][:80]}...")
        print(f"ğŸ¤– AI Used: {conv_result['ai_used']}")
        print(f"ğŸ¢ Provider: {conv_result['provider']}")
        print()
        
        # Final metrics
        final_metrics = client.get_metrics()
        print("ğŸ“Š FINAL METRICS")
        print("-" * 20)
        for key, value in final_metrics.items():
            print(f"{key}: {value}")
        print()
        
        # Analyze performance
        print("ğŸ¯ ANALYSIS")
        print("-" * 15)
        
        if conv_result['ai_used'] == 'llama-scout':
            print("âœ… Llama Scout is ACTIVE and working")
            print("âœ… Primary AI is functioning correctly")
        else:
            print("âš ï¸  Haiku fallback was used instead of Llama Scout")
            print("âš ï¸  This might indicate Llama Scout issues")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("âŒ LlamaScoutClient not available")
        return False
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        print(traceback.format_exc())
        return False

if __name__ == "__main__":
    # Set environment variables for testing
    os.environ['OPENROUTER_API_KEY_LLAMA'] = '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'
    os.environ['ANTHROPIC_API_KEY'] = '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'
    
    # Run the test
    asyncio.run(test_llama_scout_direct())