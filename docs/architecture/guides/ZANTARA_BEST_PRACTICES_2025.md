# üöÄ ZANTARA BRIDGE - Best Practices 2025
*Prontuario operativo per Analytics + AI/ML - Ready-to-deploy*

---

## 0Ô∏è‚É£ Struttura Repository (Monorepo Core + Satelliti)

Monorepo per piattaforma e contratti; micro-repo per componenti "hard" con release indipendenti (es. vector store connectors, analytics ingestion).

```
zantara-bridge/
‚îú‚îÄ .devcontainer/           # Dev env riproducibile
‚îú‚îÄ .github/workflows/       # CI/CD (GPU + cache artefatti)
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ analytics/
‚îÇ  ‚îÇ  ‚îú‚îÄ clickhouse/
‚îÇ  ‚îÇ  ‚îú‚îÄ druid/
‚îÇ  ‚îÇ  ‚îî‚îÄ dashboards/        # Grafana provisioning-as-code
‚îÇ  ‚îú‚îÄ vector_store/
‚îÇ  ‚îÇ  ‚îú‚îÄ embeddings/
‚îÇ  ‚îÇ  ‚îú‚îÄ indexing/          # HNSW/IVF param tuning
‚îÇ  ‚îÇ  ‚îî‚îÄ connectors/        # Pinecone/Weaviate/Qdrant
‚îÇ  ‚îú‚îÄ langchain/
‚îÇ  ‚îÇ  ‚îú‚îÄ chains/
‚îÇ  ‚îÇ  ‚îú‚îÄ agents/            # Orchestrazione con LangGraph
‚îÇ  ‚îÇ  ‚îî‚îÄ security/          # Guard-rails & eval
‚îÇ  ‚îî‚îÄ pipelines/
‚îÇ     ‚îú‚îÄ etl/
‚îÇ     ‚îî‚îÄ ml/
‚îú‚îÄ infrastructure/
‚îÇ  ‚îú‚îÄ terraform/
‚îÇ  ‚îî‚îÄ kubernetes/
‚îú‚îÄ tests/{unit,integration,e2e}
‚îî‚îÄ docs/{architecture,api}
```

---

## 1Ô∏è‚É£ Analytics: ClickHouse & Grafana "as-code"

### ‚úÖ Quando ClickHouse
- OLAP massivo, ingest veloce, query vettorializzate
- MergeTree/ReplicatedMergeTree per disponibilit√† e throughput (con Keeper per coordinazione/DDL distribuita)
- S3 + cache locale per tiering "caldo/freddo" (separate storage/compute e cache LRU sul disco locale)

### ‚úÖ Grafana: tutto in Git
- Provisioning YAML sotto `provisioning/dashboards` + Git Sync
- Pipeline CI per pubblicare automaticamente dashboard versionate

### ‚úÖ SLO & Allerta Sane (niente sirene inutili)
- Base su OpenTelemetry (tracce, metriche, log)
- Alert multi-burn-rate (finestra corta "fast burn" + lunga "slow burn") come da SRE workbook
- Heuristics: RED per microservizi (Requests, Errors, Duration), USE per risorse (Utilization, Saturation, Errors)

### ‚úÖ Segment/Mixpanel/Amplitude
- Mantenere Tracking Plan con Segment Protocols
- Mapping corretto `userId ‚Üí distinct_id` per Mixpanel

---

## 2Ô∏è‚É£ Data Platform (Snowflake/BigQuery) - 3 Regole Rapide

### ‚úÖ Performance & Partizionamento
- Partizionare/clusterizzare tabelle grandi
- Evitare `SELECT *` negli strumenti interattivi
- Guideline standard - non dogmi, servono indici

### ‚úÖ Data Quality & Freshness
- dbt source freshness e soglie SLA (warn/error)
- Great Expectations per convalida schema/valori via Checkpoints in CI

---

## 3Ô∏è‚É£ MLOps & CI/CD: L2 "vero" ma sobrio

### ‚úÖ Pipeline GitHub Actions

```yaml
# .github/workflows/zantara-ml.yml
name: zantara-ml
on:
  push:
    branches: [main]

jobs:
  data-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: great_expectations checkpoint run  # GE Checkpoint

  train:
    needs: data-validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: dvc repro train                      # Orchestrazione DVC
      - run: mlflow models register               # Model Registry

  update-vector-index:
    needs: train
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: python src/vector_store/indexing/update.py
```

### ‚úÖ Tooling
- DVC per dipendenze/artefatti riproducibili
- MLflow Model Registry per versioning/aliased stages (Staging/Production)
- Runner: se serve GPU, usare hosted GPU di GitHub o self-hosted dedicati

---

## 4Ô∏è‚É£ RAG & Agenti: "solido prima, furbo poi"

### ‚úÖ Orchestrazione & Stato
- LangGraph per agenti e flussi a stati (checkpointing, human-in-the-loop)

### ‚úÖ Retriever che "capiscono" il dato
- **Self-Query Retriever**: traduce domande NL in filtri su metadati del vector store
- **ParentDocumentRetriever**: recupera chunk piccoli ma risponde col "genitore" pi√π grande ‚Üí contesto stabile
- **Contextual Compression**: filtra/condensa i documenti recuperati prima del prompt finale

### ‚úÖ Cache & Costi
- OpenAI Batch API: ‚àí50% costo I/O se il lavoro non √® interattivo
- Prompt Caching (automatico): cache dei prefissi >1.024 token con sconto dedicato sui token "cached"
- Ottimo per prompt lunghi e ripetitivi

---

## 5Ô∏è‚É£ Vector DB: isolamento, cancellazione, qualit√† ricerca

### ‚úÖ Isolamento per tenant/namespace e delete davvero (Diritto all'oblio)
- **Pinecone**: `delete(ids|filter|deleteAll)` per namespace
- **Weaviate**: delete per id/filtri; multi-tenancy ‚Üí cancellazione del tenant = cancellazione di tutti gli oggetti

### ‚úÖ HNSW/IVF Parameters
- Impostare parametri di recall/latency in base al carico
- Start conservativo; misurare P@k/latency

### ‚úÖ Hybrid Search & Schema
- BM25 + vettori quando le query hanno forte componente keyword
- Named vectors & metadata: progettare lo schema dei metadati per filtrare a monte (ridurre token e latenza)

---

## 6Ô∏è‚É£ Sicurezza & Compliance (LLM + dati)

### ‚úÖ OWASP Top 10 LLM
- #1 resta Prompt Injection
- Apply allow/deny list sugli strumenti e output handling sicuro

### ‚úÖ GDPR & Privacy
- DPIA per casi ad alto rischio (GDPR art. 35) + guida ICO/EDPB
- Right-to-be-forgotten nei vector store: progettare deletion "end-to-end" (indice + sorgente)

### ‚úÖ Secrets & Access
- Vault per segreti dinamici (credenziali DB a TTL, rotazione automatica)
- AWS Secrets Manager con rotazione automatica (fino a ogni 4 ore)

---

## 7Ô∏è‚É£ Costi: FinOps per AI (GPU + token)

### ‚úÖ Misurazione & Tagging
- Misurare per progetto GPU-hours, token e storage
- Definire owner e tag standard
- Linee guida FinOps Foundation per AI (forecasting, anomalie, cost model)

### ‚úÖ Tiering Modelli
- Batch offline via Batch API (‚àí50%)
- Interattivo con modelli pi√π piccoli dove possibile
- Prompt caching per prompt lunghi ripetuti

---

## 8Ô∏è‚É£ DevX: ambienti, linting, pre-commit

### ‚úÖ Dev Container (standard 2025)
- `devcontainer.json` + Dockerfile con Python 3.11+, estensioni SQL/YAML

### ‚úÖ Gestione Pacchetti
- **uv** (Astral) per install/build velocissimi; sostituisce pip/pip-tools nei cicli CI

### ‚úÖ Lint/Format Tools
- **Ruff** (lint + formatter) ‚Üí rimpiazza combo Flake8+Black in un solo tool
- **SQLFluff** con dialetto ClickHouse per SQL coerente
- **Gitleaks** per secret-scanning
- **Prettier** per YAML/JSON

### ‚úÖ Pre-commit Configuration

```yaml
# .pre-commit-config.yaml
repos:
- repo: https://github.com/astral-sh/ruff-pre-commit
  rev: v0.6.9
  hooks:
    - id: ruff
      args: [--fix]
    - id: ruff-format
- repo: https://github.com/sqlfluff/sqlfluff
  rev: 2.3.0
  hooks:
    - id: sqlfluff-lint
    - id: sqlfluff-fix
      args: [--dialect, clickhouse]
- repo: https://github.com/gitleaks/gitleaks
  rev: v8.18.4
  hooks:
    - id: gitleaks
- repo: https://github.com/pre-commit/mirrors-prettier
  rev: v3.3.3
  hooks:
    - id: prettier
      files: "\\.(json|ya?ml)$"
```

---

## 9Ô∏è‚É£ API & Serving

### ‚úÖ Protocol & Patterns
- **gRPC** per serving modelli (IDL protobuf, streaming, efficienza)
- **GraphQL** per dashboard/aggregazioni flessibili
- **Pattern**: versioning semantico per modelli, blue/green, circuit breakers, rate limiting "token bucket"

---

## üîü Ready-to-Deploy Checklist

### A. Dev & Qualit√†
- [ ] `.devcontainer/` con Python 3.11+ e uv
- [ ] pre-commit con Ruff/SQLFluff/Gitleaks/Prettier

### B. Observability
- [ ] `src/analytics/dashboards/` + provisioning Grafana in YAML
- [ ] Workflow "deploy dashboards"
- [ ] Alert multi-burn-rate sugli SLO principali (fast vs slow)

### C. MLOps
- [ ] Workflow CI con GE Checkpoint ‚Üí DVC ‚Üí MLflow Registry
- [ ] Job separato per aggiornamento embeddings (idempotente + metriche P@k)

### D. AI Cost-Aware
- [ ] Endpoint batch per job non interattivi (‚àí50%)
- [ ] Prompt caching per prompt ripetuti

### E. Security
- [ ] Policy OWASP-LLM in `src/langchain/security/` con test di prompt-injection
- [ ] Secret management: Vault/Secrets Manager con rotazione automatica (policy 30‚Äì90 gg)

---

## üìÖ Roadmap 30/60/90

### üéØ 0‚Äì30 giorni
- [ ] DevContainer + pre-commit
- [ ] Grafana provisioning
- [ ] GE/dbt freshness sugli stream critici
- [ ] Policy OWASP-LLM "v1"

### üéØ 30‚Äì60 giorni
- [ ] LangGraph per orchestrare agenti RAG
- [ ] Self-Query/ParentDocument/Compression
- [ ] Batch API per job offline

### üéØ 60‚Äì90 giorni
- [ ] ClickHouse con ReplicatedMergeTree + S3 cache
- [ ] Allerta multi-burn-rate end-to-end
- [ ] Processo DPIA e cancellazione tenant "one-click"

---

## ‚ö†Ô∏è Nota sulle Affermazioni "Troppo Belle"

Alcuni numeri assoluti (tipo "20√ó pi√π veloce sempre", "hit-rate cache = 68%") dipendono dal vostro carico, schema e prompt.

**Tenete le percentuali per gli OKR, non per le decisioni tecniche.**

Misurate su dataset e traffico vostri con metriche chiare:
- P@k
- Latenza p95
- Costo/1000 richieste

Poi fissate soglie realistiche.

---

*Documento creato: 2025-09-25*
*Versione: 1.0*
*Status: Ready for Implementation*