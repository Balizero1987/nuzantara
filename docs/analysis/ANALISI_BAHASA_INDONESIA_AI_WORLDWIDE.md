# Analisi Mondiale: Fluidit√† e Naturalezza del Bahasa Indonesia nelle AI

**Data**: 16 Novembre 2025
**Autore**: Analisi Tecnica Nuzantara
**Obiettivo**: Valutare la qualit√† del bahasa indonesia nelle AI pi√π diffuse e proporre soluzioni

---

## Executive Summary

Questa analisi esamina la capacit√† delle AI pi√π diffuse (GPT-4, Claude, Llama, e modelli regionali) di produrre bahasa indonesia fluido, naturale e comprensibile da madrelingua. I risultati rivelano problemi significativi che richiedono interventi immediati.

### Risultati Chiave

- **GPT-4/ChatGPT**: Performance 83.1% su benchmark ma rigidit√† nel linguaggio pratico
- **Claude**: Buone capacit√† ma mancanza di naturalezza culturale
- **Llama 2/3**: Limitazioni severe ammesse da Meta per lingue non-inglesi
- **Llama 4 Scout**: Miglioramenti significativi con 10M token di contesto
- **Modelli Regionali** (SEA-LION, SahabatAI, Komodo): Performance superiore su espressioni idiomatiche e contesto culturale

**Il problema √® reale e diffuso**: le AI mainstream hanno un bahasa indonesia "ingessato" che risulta incomprensibile o innaturale per team indonesiani.

---

## 1. Stato dell'Arte: Performance delle AI Mainstream

### 1.1 ChatGPT / GPT-4

**Performance Tecnica**:
- GPT-4: 83.1% su benchmark tecnici (vs 85.5% in inglese)
- GPT-3.5: 70.1% in inglese, non specificato per indonesiano
- Miglioramento del 13% rispetto a GPT-3.5

**Problemi Critici**:
```
‚ùå Training data limitato: solo 0.6% del web √® in indonesiano (vs 58.8% inglese)
‚ùå Difficolt√† con dialetti e lingue regionali (700+ lingue in Indonesia)
‚ùå Risposte brevi e irrilevanti in contesti pratici
‚ùå Mancanza di conoscenza locale e culturale
‚ùå Registro linguistico rigido e innaturale
```

**Fonte**: Gojek Engineering, GLAIR.AI, Datasaur

### 1.2 Meta Llama 2/3

**Ammissioni Ufficiali di Meta**:
> "Llama 2 remains fragile and should be used with caution for non-English users"
> "Most training data is in English, it may not be suitable for use in other languages"

**Problemi Documentati**:
- Training prevalentemente in inglese
- Fragilit√† confermata per indonesiano
- Performance non garantita

**Fonte**: Meta Official Documentation, Nature Journal

### 1.3 Claude (Anthropic)

**Performance**:
- Comprensione avanzata in contesti business
- Buona adattabilit√†

**Problemi**:
- Mancanza di benchmark specifici pubblici per bahasa indonesia
- Bias verso inglese nel training
- Limitata naturalezza in espressioni colloquiali

**Nota**: Il progetto Nuzantara ha riscontrato problemi di naturalezza nei test interni con Claude Code

### 1.4 Llama 4 Scout (109B MoE, 17B active)

**Vantaggi**:
- ‚úÖ Contesto esteso: 10M token (50x Claude Haiku)
- ‚úÖ 100% success rate su benchmark ZANTARA
- ‚úÖ Costo ridotto: $0.20/$0.20 per 1M token (92% pi√π economico di Haiku)

**Performance su Nuzantara**:
- Utilizzato come primary AI nel progetto
- Fallback su Claude Haiku 4.5 per query complesse

---

## 2. Benchmark e Dataset Accademici

### 2.1 IndoNLU (Indonesian Natural Language Understanding)

**Caratteristiche**:
- 12 task di comprensione linguistica
- Diversi livelli di complessit√†
- Domini e stili variati
- Prima risorsa completa per training e valutazione

**Dataset Indo4B**:
- Raccolto da social media, blog, news, siti web
- Pre-training per IndoBERT
- Ampia copertura di registri linguistici

**Fonte**: Gojek Engineering, ArXiv 2009.05387

### 2.2 IndoNLG (Indonesian Natural Language Generation)

**Caratteristiche**:
- 6 task di generazione (summarization, Q&A, chat)
- 3 lingue: indonesiano, giavanese, sundanese
- Focus su lingue a basse risorse

**Fonte**: ArXiv 2104.08200

### 2.3 IndoLEM (Indonesian Language Evaluation Montage)

**Caratteristiche**:
- 7 task: morpho-syntax, semantics, discourse
- Dataset di benchmark con IndoBERT
- Stato dell'arte su task NLP indonesiani

**Limitazioni**:
- Dataset limitato rispetto a risorse inglesi
- Mancanza di standardizzazione
- Scarsit√† di risorse linguistiche

**Fonte**: ACL Anthology, ResearchGate

### 2.4 IndoCareer (Vocational & Professional Exams)

**Caratteristiche**:
- 8,834 domande a scelta multipla
- 6 settori professionali
- Contesto locale indonesiano ricco
- Focus su esami di certificazione

**Fonte**: ArXiv 2409.08564

---

## 3. Sfide Linguistiche Specifiche del Bahasa Indonesia

### 3.1 Registro Formale vs Informale

**Problema Critico**:
Le AI tendono a produrre indonesiano eccessivamente formale o rigido, inadatto a conversazioni naturali.

**Differenze Chiave**:

| Aspetto | Formale | Informale |
|---------|---------|-----------|
| Contesto | Discorsi pubblici, documenti ufficiali | Conversazioni quotidiane |
| Pronomi | Evitati, sostituiti da nomi/titoli | Saya, kamu, aku |
| Lessico | Senza colloquialismi | Include slang, dialetti |
| Imperativi | tolong, coba, harap | Diretto |

**Impatto sulle AI**:
```
‚ùå GPT/Claude tendono a usare sempre registro formale
‚ùå Mancanza di adattamento al contesto
‚ùå Perdita di naturalezza
```

### 3.2 Sistema di Onorificenza e Gerarchia

**Complessit√†**:
- Pronomi marcati per familiarit√† e formalit√†
- Titoli obbligatori in contesti formali (Pak/Bu, Bapak/Ibu)
- Enfasi su livelli di formalit√† come distanza sociale

**Lingue Regionali (Giavanese, Sundanese)**:
- Sistemi di speech levels multipli basati su:
  - Distanza sociale
  - Et√†
  - Status
- Unggah-Ungguh Basa (etichetta linguistica giavanese)

**Problema per le AI**:
```
‚ùå Difficolt√† a scegliere il livello appropriato
‚ùå Mancanza di sensibilit√† culturale
‚ùå Errori nell'uso di titoli e onorifici
```

### 3.3 Espressioni Idiomatiche e Slang

**Sfida**:
Le AI mainstream mancano di comprensione profonda di:
- Espressioni idiomatiche locali
- Slang regionale (es. "pekok" in giavanese = stupido)
- Riferimenti culturali specifici
- Code-mixing (indonesiano + giavanese/sundanese + inglese)

**Esempio da IndoJavE**:
```
‚úÖ Modelli specializzati classificano correttamente "pekok" come negativo
‚ùå GPT/Claude potrebbero non riconoscerlo
```

### 3.4 Multilinguismo e Code-Mixing

**Realt√† Indonesiana**:
- 700+ lingue parlate nell'arcipelago
- Code-mixing frequente in social media
- Spelling non standardizzato
- Nuance regionali

**Problema**:
```
‚ùå AI trainati principalmente su bahasa indonesia standard
‚ùå Difficolt√† con mixing linguistico naturale
‚ùå Incomprensione di dialetti regionali
```

---

## 4. Modelli LLM Regionali Specializzati

### 4.1 SEA-LION (Southeast Asian Languages In One Network)

**Sviluppatore**: AI Singapore
**Caratteristiche**:
- 11 lingue del sud-est asiatico (include indonesiano)
- Versioni: v3, v3.5, v4
- Base models: Llama-SEA-LION-v3-8B-IT, Gemma-SEA-LION-v3-9B-IT

**Performance v4** (2025):
```
‚úÖ #5 su 55 modelli instruct su SEA-HELM benchmark
‚úÖ #1 tra modelli open-source sotto 200B parametri
‚úÖ Comparabile a GPT-4o e Deepseek 671B R1
‚úÖ Supera GPT-4o-mini, Llama 3.3 70B, Qwen 2.5 72B
```

**Vantaggi per Indonesiano**:
- Comprensione dettagli locali e nuance culturali
- Performance comparabile a GPT-4o-mini su task generali
- Significativamente superiore su task domain-specific
- Maggiore sensibilit√† culturale e contesto indonesiano

**Fonte**: SEA-LION.ai, NVIDIA Technical Blog

### 4.2 SahabatAI-v1

**Sviluppatore**: Comunit√† indonesiana
**Caratteristiche**:
- Fine-tuning su instruction-completion pairs in contesti indonesiani
- Focus su linguaggio informale, espressioni idiomatiche, conoscenza culturale

**Performance** (Benchmark 2025 vs SEA-LIONv3):
```
‚úÖ Superiore in task che richiedono comprensione sfumata del bahasa
‚úÖ Fluidit√† e accuratezza superiori
‚úÖ Riconoscimento eccellente di slang regionale
‚úÖ Interpretazione accurata di espressioni idiomatiche
‚úÖ Risposte culturalmente risonanti e rilevanti
```

**Fonte**: We SUPA AI Blog, Medium

### 4.3 Komodo-7B

**Sviluppatore**: Yellow.AI
**Caratteristiche**:
- Basato su Llama-2
- 11 lingue regionali indonesiane:
  - Acehnese, Balinese, Banjarese, Buginese
  - Dayak Ngaju, Javanese, Lampungnese
  - Madurese, Minangkabau, Sundanese, Toba Batak

**Performance** (Marzo 2024):
```
‚úÖ Supera Cohere Aya-101
‚úÖ Supera MBZUAI Bactrian-X-llama-7B
‚úÖ Supera Qwen-1.5
‚úÖ Supera Mistral Mixtral-8x7B-Instruct-v0.1
‚úÖ Supera AI Singapore Indonesian SEA-LION
```

**Vantaggi Unici**:
- Gestione di slang misto indonesiano-sundanese
- Comprensione riferimenti culturali indonesiani
- Contesti business specifici
- Espressioni colloquiali che modelli generici non capiscono

**Fonte**: Yellow.AI, Slator

### 4.4 Cendol Collection

**Caratteristiche**:
- Famiglia di LLM indonesiani (decoder-only + encoder-decoder)
- Diverse dimensioni
- Dataset di instruction-tuning su larga scala

**Limitazioni Riconosciute**:
```
‚ùå Performance eccellente su task NLP tecnici
‚ùå MA: carenza nella cattura di conoscenza locale e valori culturali
```

**Fonte**: ArXiv 2404.06138

---

## 5. Problemi Identificati nei Test Nuzantara

### 5.1 Test Interno con 70 Domande Difficili

**File**: `apps/intel-scraping/domande_indonesiano.md`

**Categorie**:
1. Immigrazione (10 domande - KITAS, KITAP, visa)
2. Codice Penale (10 domande - KUHP, crimini)
3. Company e Licenze Business (10 domande - PT, PT PMA, OSS)
4. Tax (10 domande - PPh, PPN, transfer pricing)
5. Legal Property (10 domande - HGB, HGU, land rights)
6. Combo Topics (10 domande - scenari multi-dominio)

**Complessit√†**:
- Terminologia legale tecnica indonesiana
- Riferimenti a regolamenti specifici (Undang-Undang, Peraturan Pemerintah)
- Contesto business reale
- Domande lunghe e complesse

**Esempio**:
```
"Menurut Pasal 31 Peraturan Pemerintah Nomor 31 Tahun 2013 tentang
Peraturan Pelaksanaan Undang-Undang Nomor 6 Tahun 2011 tentang
Keimigrasian, khususnya untuk kategori investor dengan nilai
investasi minimal 1 miliar rupiah?"
```

### 5.2 Risultati Test Multilingue

**File**: `apps/backend-rag/test_multilingual_quality.py`

**Focus**:
- Fluidit√† (30% peso)
- Accuratezza (25% peso)
- Appropriatezza tono (25% peso)
- Consapevolezza culturale (20% peso)

**Criteri di Qualit√†**:
```
1. Flusso linguistico naturale (non robotico/meccanico)
2. Informazioni corrette
3. Tono appropriato (professionale/casual/caldo)
4. Intelligenza culturale
```

**Problemi Riscontrati dal Team**:
> "Claude Code (preparando domande), Llama e ChatGPT avevano
> bahasa indonesia ingessato a tal punto che il team non capiva"

**Indicatori di Problemi**:
- Linguaggio troppo formale per contesti casual
- Mancanza di espressioni idiomatiche naturali
- Strutture sintattiche calchate dall'inglese
- Perdita di sfumature culturali

---

## 6. Analisi delle Cause Radice

### 6.1 Squilibrio nel Training Data

**Distribuzione Web Content** (Statista, Gennaio 2023):
```
Inglese:     58.8% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Indonesiano:  0.6% ‚ñà
```

**Impatto**:
- AI mainstream hanno 98x pi√π dati inglesi che indonesiani
- Bias strutturale verso pattern linguistici inglesi
- Mancanza di esposizione a variabilit√† indonesiana

### 6.2 Mancanza di Diversit√† nei Dati Indonesiani

**Problemi**:
1. Prevalenza di testo formale/scritto vs conversazionale
2. Sotto-rappresentazione di dialetti regionali
3. Scarsa inclusione di code-mixing naturale
4. Mancanza di contesto culturale locale

**Conseguenza**:
```
AI producono indonesiano "da libro di testo" invece che naturale
```

### 6.3 Evaluation Bias

**Problema**:
- Benchmark esistenti (IndoNLU, IndoLEM) si concentrano su task tecnici
- Poca valutazione di fluidit√† e naturalezza da parte di native speakers
- Metriche automatiche non catturano qualit√† linguistica percepita

**Esempio**:
```
‚úÖ GPT-4: 83.1% su benchmark tecnico
‚ùå GPT-4: incomprensibile per team indonesiani in uso pratico
```

### 6.4 Architettura di Fine-Tuning

**Limitazione**:
Le AI mainstream usano fine-tuning generico che non cattura:
- Sensibilit√† ai registri linguistici
- Contesto socio-culturale indonesiano
- Espressioni idiomatiche regionali
- Dinamiche di code-mixing

**Soluzione nei Modelli Regionali**:
```
‚úÖ Fine-tuning su dataset indonesiani specifici
‚úÖ Inclusion di instruction pairs in contesti locali
‚úÖ Training su social media, blog, conversazioni reali
```

---

## 7. Soluzioni e Raccomandazioni

### 7.1 SOLUZIONE IMMEDIATA: Utilizzo di Modelli Regionali

**Raccomandazione Primaria**:

#### Opzione A: SEA-LION v4 (Consigliato per Production)
```yaml
Modello: SEA-LION v4 (Gemma-SEA-LION-v3-9B)
Vantaggi:
  - #1 tra open-source sotto 200B parametri
  - Performance comparabile a GPT-4o
  - Comprensione profonda di contesto indonesiano
  - Supporto multilingue (11 lingue SEA)
Deployment: Via API o self-hosted
Costo: Open-source (hosting proprio)
```

#### Opzione B: SahabatAI-v1 (Consigliato per Fluidit√†)
```yaml
Modello: SahabatAI-v1
Vantaggi:
  - Superiore su slang regionale e idiomi
  - Eccellente fluidit√† linguistica
  - Risposte culturalmente appropriate
  - Fine-tuning su contesti indonesiani
Deployment: Verificare disponibilit√† API
```

#### Opzione C: Komodo-7B (Consigliato per Lingue Regionali)
```yaml
Modello: Komodo-7B-Instruct
Vantaggi:
  - 11 lingue regionali indonesiane
  - Migliore per code-mixing naturale
  - Comprensione dialetti (Giavanese, Balinese, etc.)
Deployment: Via Yellow.AI o self-hosted
```

**Implementazione nel Progetto Nuzantara**:
```python
# Configurazione consigliata multi-model
PRIMARY_MODEL = "SEA-LION-v4"  # Per accuratezza e performance
FALLBACK_1 = "SahabatAI-v1"    # Per fluidit√† massima
FALLBACK_2 = "Llama-4-Scout"   # Per contesto esteso
FALLBACK_3 = "Claude-Haiku-4.5" # Per query complesse
```

### 7.2 SOLUZIONE A MEDIO TERMINE: Fine-Tuning Customizzato

**Strategia**:

1. **Raccolta Dataset Indonesiano di Qualit√†**
   ```
   Fonti:
   - Conversazioni business reali (con consenso)
   - Social media indonesiani (Twitter, Instagram, Kaskus)
   - News e blog locali
   - Forum e community indonesiane
   - Interazioni WhatsApp Business (anonimizzate)
   ```

2. **Creazione Preference Dataset**
   ```
   Stile: IndoPref (522 prompt da native speakers)
   Focus:
   - Naturalezza contestuale
   - Appropriatezza culturale
   - Variet√† di registri (formale/informale)
   - Code-mixing naturale
   ```

3. **Fine-Tuning su Base Model Robusto**
   ```
   Base: Llama 4, Mistral 7B, o Gemma
   Metodo:
   - Supervised Fine-Tuning (SFT)
   - Direct Preference Optimization (DPO)
   - Reinforcement Learning from Human Feedback (RLHF)
   ```

4. **Validazione con Native Speakers**
   ```
   Team: Coinvolgere team indonesiano del progetto
   Metriche:
   - Comprensibilit√† (1-10)
   - Naturalezza (1-10)
   - Appropriatezza culturale (1-10)
   - Preferenza vs AI mainstream
   ```

**Risorse Necessarie**:
- 10K-50K esempi di conversazioni di qualit√†
- 3-6 mesi di raccolta e annotazione
- Compute: GPU A100 x4-8 per 1-2 settimane
- Budget: $5K-$15K (cloud compute + annotazione)

### 7.3 SOLUZIONE ARCHITETTURALE: Prompt Engineering Avanzato

**Implementazione nel Sistema Esistente**:

#### 7.3.1 Enhancement del System Prompt

**File**: `apps/backend-rag/backend/prompts/zantara_v6_llama4_optimized.md`

**Aggiunte Consigliate**:

```markdown
# BAHASA INDONESIA - NATURAL COMMUNICATION GUIDELINES

## Tone Adaptation Matrix
- Business formal ‚Üí Use "Bapak/Ibu", avoid slang, maintain professional distance
- Business casual ‚Üí Use "Pak/Bu", friendly but respectful
- Casual inquiry ‚Üí Use "Saya/Anda", warm and helpful tone
- Urgent help ‚Üí Direct, empathetic, solution-focused

## Natural Expression Patterns

### ‚úÖ DO - Natural Indonesian:
- "Saya bisa bantu Anda dengan setup PT PMA"
- "Prosesnya kurang lebih 2-3 minggu ya"
- "Kalau ada pertanyaan lagi, silakan hubungi kami"
- "Untuk KITAS investor, persyaratannya cukup straightforward"

### ‚ùå DON'T - Stiff/Robotic Indonesian:
- "Saya akan membantu Anda dalam proses pendirian PT PMA"
- "Durasi proses adalah 2-3 minggu"
- "Apabila terdapat pertanyaan tambahan, dipersilakan menghubungi"
- "Untuk KITAS investor, persyaratan yang diperlukan adalah..."

## Idiomatic Expressions (Use When Appropriate):
- "Gampang kok" (It's easy) - for reassurance
- "Santai aja" (Relax) - for calming concerns
- "Itu dia" (Exactly) - for agreement
- "Soalnya..." (Because...) - for explanations
- "Jadi gini..." (So here's the thing...) - for transitions

## Cultural Intelligence:
- Use patience language for bureaucratic processes
- Acknowledge "proses" as part of Indonesian business culture
- Show understanding of face-saving needs
- Reference Tri Hita Karana when relevant (Bali context)
```

#### 7.3.2 Dynamic Language Register Selection

**Implementazione**:

```python
# apps/backend-ts/src/services/MultiLanguageSystem.ts

class IndonesianRegisterSelector:
    """Select appropriate Indonesian register based on context"""

    def detect_formality_level(self, query: str, user_profile: dict) -> str:
        """
        Returns: 'very_formal', 'formal', 'neutral', 'casual', 'very_casual'
        """
        indicators = {
            'very_formal': [
                'peraturan', 'undang-undang', 'pasal',
                'kepada yth', 'dengan hormat'
            ],
            'formal': [
                'mohon informasi', 'terima kasih',
                'bapak/ibu', 'saya ingin'
            ],
            'casual': [
                'gimana', 'dong', 'nih', 'sih',
                'mau', 'bisa ga'
            ],
            'very_casual': [
                'gue', 'lu', 'gw', 'bro',
                'cuy', 'wkwk'
            ]
        }

        # Score each level
        scores = {}
        for level, markers in indicators.items():
            scores[level] = sum(1 for m in markers if m in query.lower())

        # Select highest scoring level
        return max(scores, key=scores.get) if max(scores.values()) > 0 else 'neutral'

    def build_register_instructions(self, formality: str) -> str:
        """Build prompt instructions for specific register"""
        instructions = {
            'very_formal': """
                Gunakan bahasa Indonesia formal tingkat tinggi:
                - Hindari kontraksi dan slang
                - Gunakan struktur kalimat kompleks
                - Referensi peraturan dengan tepat
            """,
            'formal': """
                Gunakan bahasa Indonesia formal standar:
                - Professional dan respectful
                - Pak/Bu untuk sapaan
                - Kalimat lengkap dan jelas
            """,
            'neutral': """
                Gunakan bahasa Indonesia standar:
                - Friendly tapi professional
                - Natural dan mudah dipahami
                - Mix formal dan informal sesuai konteks
            """,
            'casual': """
                Gunakan bahasa Indonesia casual:
                - Warm dan approachable
                - Boleh pakai kontraksi natural
                - Ekspresi sehari-hari OK
            """,
            'very_casual': """
                Gunakan bahasa Indonesia very casual:
                - Like talking to a friend
                - Slang umum boleh
                - Emoji appropriate
            """
        }
        return instructions.get(formality, instructions['neutral'])
```

#### 7.3.3 Cultural Context Injection

**Enhancement del CulturalRAGService**:

```python
# apps/backend-rag/backend/services/cultural_rag_service.py

class EnhancedCulturalRAGService:
    """Enhanced cultural context with language patterns"""

    async def get_cultural_context(
        self,
        query: str,
        language: str = "id"
    ) -> dict:
        """Get cultural context + language pattern guidance"""

        # Existing cultural retrieval
        cultural_context = await self.retrieve_cultural_knowledge(query)

        # NEW: Add language pattern guidance
        if language == "id":
            language_guidance = await self._get_indonesian_patterns(query)
            cultural_context["language_patterns"] = language_guidance

        return cultural_context

    async def _get_indonesian_patterns(self, query: str) -> dict:
        """Retrieve appropriate Indonesian language patterns"""

        # Detect domain
        domain = self._detect_domain(query)  # visa, tax, business, etc.

        # Get domain-specific patterns from knowledge base
        patterns = {
            "visa": {
                "natural_phrases": [
                    "Untuk KITAS, prosesnya kira-kira...",
                    "Biasanya perlu waktu sekitar...",
                    "Dokumen yang diperlukan antara lain..."
                ],
                "avoid": [
                    "Adapun persyaratan yang harus dipenuhi adalah...",
                    "Durasi pemrosesan memerlukan waktu..."
                ]
            },
            "business": {
                "natural_phrases": [
                    "Kalau mau buka PT PMA, langkah pertama...",
                    "Modal yang diperlukan sekitar...",
                    "Prosesnya cukup straightforward kok"
                ],
                "avoid": [
                    "Untuk pendirian PT PMA diperlukan modal minimal...",
                    "Tahapan yang harus dilakukan meliputi..."
                ]
            }
        }

        return patterns.get(domain, patterns["business"])
```

### 7.4 SOLUZIONE TECNICA: Evaluation Framework

**Implementazione Sistema di Valutazione Continua**:

#### 7.4.1 Native Speaker Feedback Loop

```python
# apps/backend-rag/backend/services/language_quality_service.py

class LanguageQualityEvaluator:
    """Continuous evaluation of Indonesian language quality"""

    async def evaluate_response(
        self,
        response: str,
        expected_register: str,
        native_speaker_id: str = None
    ) -> dict:
        """
        Evaluate response quality on multiple dimensions

        Returns quality scores and feedback
        """

        scores = {
            "fluency": await self._evaluate_fluency(response),
            "naturalness": await self._evaluate_naturalness(response),
            "register_match": await self._evaluate_register(
                response, expected_register
            ),
            "cultural_appropriateness": await self._evaluate_cultural(response)
        }

        # Flag for native speaker review if below threshold
        if any(score < 7.0 for score in scores.values()):
            await self._request_native_review(
                response, scores, native_speaker_id
            )

        return scores

    async def _evaluate_naturalness(self, response: str) -> float:
        """
        Check for unnaturalness indicators:
        - Overly formal structures in casual context
        - Direct translations from English patterns
        - Lack of idiomatic expressions
        - Robotic phrasing
        """

        # Unnaturalness patterns
        unnatural_patterns = [
            r"adapun .* adalah",  # bureaucratic
            r"diperlukan .* untuk",  # passive overuse
            r"dalam hal .* maka",  # legal language in casual context
            r"terdapat .* yang",  # written-only forms
        ]

        unnatural_count = sum(
            len(re.findall(pattern, response, re.IGNORECASE))
            for pattern in unnatural_patterns
        )

        # Natural expression patterns
        natural_patterns = [
            r"bisa.*dengan",
            r"kalau.*mau",
            r"untuk.*prosesnya",
            r"kurang lebih",
            r"silakan",
        ]

        natural_count = sum(
            len(re.findall(pattern, response, re.IGNORECASE))
            for pattern in natural_patterns
        )

        # Score: higher natural, lower unnatural = higher score
        if len(response) == 0:
            return 5.0

        naturalness_ratio = (natural_count - unnatural_count) / (len(response) / 100)
        score = max(0, min(10, 5 + naturalness_ratio * 2))

        return score
```

#### 7.4.2 A/B Testing Framework

```python
# apps/backend-rag/backend/services/ab_testing_service.py

class IndonesianABTestingService:
    """A/B test different models/prompts for Indonesian quality"""

    async def run_comparative_test(
        self,
        query: str,
        models: list[str]  # e.g., ["gpt-4", "sea-lion-v4", "sahabat-ai"]
    ) -> dict:
        """
        Run same query through multiple models
        Collect native speaker preferences
        """

        responses = {}
        for model in models:
            responses[model] = await self._get_response(query, model)

        # Randomize order for presentation
        randomized = list(responses.items())
        random.shuffle(randomized)

        # Present to native speaker for rating
        evaluation = await self._collect_native_evaluation(
            query, randomized
        )

        return {
            "query": query,
            "responses": responses,
            "evaluation": evaluation,
            "winner": self._determine_winner(evaluation)
        }
```

### 7.5 SOLUZIONE ORGANIZZATIVA: Native Speaker Team Integration

**Raccomandazioni**:

1. **Weekly Language Quality Reviews**
   ```
   Frequenza: Settimanale
   Team: 2-3 native speakers indonesiani
   Durata: 1 ora
   Focus: Review 20-30 risposte AI per naturalezza
   Output: Feedback per miglioramento prompt/model
   ```

2. **Response Quality Criteria**
   ```
   Checklist per ogni risposta:
   [ ] √à comprensibile immediatamente?
   [ ] Suona naturale (non tradotto)?
   [ ] Usa il registro appropriato?
   [ ] Include espressioni idiomatiche appropriate?
   [ ] √à culturalmente sensibile?
   [ ] Evita phrasing "ingessato"?
   ```

3. **Feedback Integration Pipeline**
   ```
   Native feedback ‚Üí Annotation ‚Üí Fine-tuning dataset ‚Üí Model update
   Cycle time: 2-4 settimane
   ```

---

## 8. Roadmap di Implementazione

### FASE 1: IMMEDIATA (Settimana 1-2)

**Azioni**:
```
[‚úì] Documentare il problema (questo documento)
[ ] Deploy SEA-LION v4 o SahabatAI come modello primario per indonesiano
[ ] Implementare prompt enhancement (Section 7.3.1)
[ ] Setup A/B testing basico (GPT-4 vs SEA-LION vs SahabatAI)
[ ] Collect 50 test queries reali dal team
```

**Deliverable**:
- Modello regionale in produzione
- Prompt ottimizzato v7.0
- Baseline quality metrics

**Effort**: 20-30 ore ingegneria

### FASE 2: BREVE TERMINE (Mese 1-2)

**Azioni**:
```
[ ] Implementare dynamic register selection (Section 7.3.2)
[ ] Enhancement CulturalRAGService con language patterns (Section 7.3.3)
[ ] Setup evaluation framework automatico (Section 7.4.1)
[ ] Raccogliere 500 query-response pairs valutati da native speakers
[ ] Weekly language quality reviews con team indonesiano
```

**Deliverable**:
- Sistema di adattamento automatico del registro
- Framework di valutazione continua
- Dataset di 500 esempi annotati

**Effort**: 60-80 ore ingegneria + 10 ore/week team review

### FASE 3: MEDIO TERMINE (Mese 3-6)

**Azioni**:
```
[ ] Raccogliere 5K-10K conversazioni indonesiane di qualit√†
[ ] Annotare con native speakers per naturalezza
[ ] Fine-tune base model (Llama 4 o Mistral 7B)
[ ] Extensive A/B testing: fine-tuned vs SEA-LION vs GPT-4
[ ] Deploy custom model se performance superiore >15%
```

**Deliverable**:
- Custom Indonesian LLM per Nuzantara
- Performance superiore a modelli mainstream
- Documentazione completa

**Effort**: 150-200 ore ingegneria + $5K-$10K compute

### FASE 4: LUNGO TERMINE (Mese 6+)

**Azioni**:
```
[ ] Continuous data collection pipeline
[ ] Automated RLHF loop con native speaker feedback
[ ] Expansion a dialetti regionali (Giavanese, Balinese per contesto Bali)
[ ] Pubblicazione paper/case study su Indonesian LLM quality
[ ] Open-source contribution a community
```

**Deliverable**:
- Self-improving Indonesian AI system
- Industry leadership su Indonesian NLP
- Community contribution

**Effort**: Ongoing

---

## 9. Metriche di Successo

### KPI Primari

1. **Comprensibilit√† Team** (Target: >95%)
   ```
   Domanda: "Il team indonesiano capisce immediatamente la risposta?"
   Baseline attuale: ~60-70% (stimato dal problema riportato)
   Target Fase 1: >85%
   Target Fase 3: >95%
   ```

2. **Naturalness Score** (Target: >8.5/10)
   ```
   Valutazione native speaker su scala 1-10
   Baseline: ~5-6/10 (GPT-4, Claude)
   Target Fase 1: >7.0/10
   Target Fase 3: >8.5/10
   ```

3. **Register Appropriateness** (Target: >90%)
   ```
   % risposte con registro linguistico corretto per contesto
   Baseline: ~50-60%
   Target Fase 1: >75%
   Target Fase 3: >90%
   ```

4. **Cultural Resonance** (Target: >8.0/10)
   ```
   Sensibilit√† culturale e appropriatezza
   Baseline: ~5-6/10
   Target Fase 3: >8.0/10
   ```

### KPI Secondari

5. **Response Fluency** (automated metric)
6. **Idiom Usage Rate** (presenza espressioni idiomatiche)
7. **Formality Mismatch Rate** (% risposte con registro sbagliato)
8. **User Satisfaction** (feedback esplicito utenti)

---

## 10. Costi e ROI

### Investimento Stimato

| Fase | Tempo | Costo Compute | Costo Personale | Totale |
|------|-------|---------------|-----------------|--------|
| Fase 1 | 2 settimane | $0 | $2K | $2K |
| Fase 2 | 2 mesi | $500 | $8K | $8.5K |
| Fase 3 | 4 mesi | $5K-10K | $15K | $20K-25K |
| **TOTALE 6 mesi** | | **$5.5K-10.5K** | **$25K** | **$30.5K-35.5K** |

### ROI Atteso

**Benefici Quantificabili**:
1. **Riduzione incomprensioni**: -70% query di clarification da team
2. **Aumento efficienza**: +40% velocit√† decision-making
3. **Miglior customer satisfaction**: +30% NPS da utenti indonesiani
4. **Riduzione churn**: -25% abbandono da frustrazione linguistica

**Benefici Strategici**:
- Leadership tecnico su Indonesian AI in settore business advisory
- Competitive advantage vs servizi che usano GPT/Claude standard
- Possibilit√† di espansione in altri mercati SEA
- IP value da custom model e dataset

**Break-even**: 3-4 mesi (se acquisizione anche solo 10 clienti extra grazie a qualit√† superiore)

---

## 11. Rischi e Mitigazioni

### Rischio 1: Modelli Regionali Non Disponibili
**Probabilit√†**: Media
**Impatto**: Alto
**Mitigazione**:
- Contattare AI Singapore per accesso SEA-LION v4
- Testare Komodo-7B via Yellow.AI
- Fallback: prompt engineering aggressivo su Llama 4 Scout

### Rischio 2: Fine-Tuning Non Migliora Abbastanza
**Probabilit√†**: Media
**Impatto**: Medio
**Mitigazione**:
- Usare modelli regionali pre-trained come base
- Extensive validation con native speakers prima del deployment
- Mantenere opzione di ensemble (modelli multipli)

### Rischio 3: Costi Compute Eccessivi
**Probabilit√†**: Bassa
**Impatto**: Medio
**Mitigazione**:
- Usare modelli open-source (SEA-LION, Komodo)
- Self-hosting su infra esistente
- Ottimizzazione con quantization (4-bit)

### Rischio 4: Mancanza Expertise Linguistico
**Probabilit√†**: Bassa (team indonesiano presente)
**Impatto**: Alto
**Mitigazione**:
- Coinvolgimento attivo team indonesiano
- Consulenza con linguisti indonesiani se necessario
- Partnership con universit√† indonesiane

---

## 12. Conclusioni

### Sintesi Esecutiva

**Il problema √® reale e documentato**:
- GPT-4, Claude, Llama 2/3 producono bahasa indonesia "ingessato" e innaturale
- Training data limitato (0.6% vs 58.8% inglese)
- Mancanza di sensibilit√† a registri, cultura, idiomi
- Team indonesiani faticano a capire le risposte

**Soluzioni esistono e sono implementabili**:
- Modelli regionali (SEA-LION v4, SahabatAI, Komodo) mostrano performance superiori
- Prompt engineering avanzato pu√≤ migliorare significativamente
- Fine-tuning customizzato √® feasible con investment ragionevole
- Native speaker integration √® critica per successo

**Raccomandazione Finale**:

```
PRIORIT√Ä 1 (Immediate): Deploy SEA-LION v4 o SahabatAI-v1
PRIORIT√Ä 2 (Settimana 1-2): Enhanced prompting + register adaptation
PRIORIT√Ä 3 (Mese 1-2): Evaluation framework + native speaker reviews
PRIORIT√Ä 4 (Mese 3-6): Custom fine-tuning su dataset proprietario
```

**Impact Atteso**:
- Da ~60% a >95% comprensibilit√† team
- Da ~5/10 a >8.5/10 naturalness score
- Competitive advantage significativo nel mercato indonesiano
- Foundation per leadership tecnico su Indonesian NLP

---

## 13. Riferimenti

### Paper Accademici
1. Wilie et al. (2020). "IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding". ArXiv 2009.05387
2. Koto et al. (2020). "IndoLEM and IndoBERT: A Benchmark Dataset and Pre-trained Language Model for Indonesian NLP". COLING 2020
3. Aji et al. (2022). "IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural Language Generation". ArXiv 2104.08200
4. Cahyawijaya et al. (2024). "Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages". ArXiv 2404.06138

### Reports Industry
5. Gojek Engineering (2020). "IndoNLU ‚Äî A benchmark for Bahasa Indonesia NLP"
6. GLAIR.AI (2023). "Challenge ChatGPT for Bahasa Indonesia"
7. Datasaur (2023). "ChatGPT for Bahasa Indonesia"
8. We SUPA AI Blog (2025). "Evaluating LLMs for Bahasa Indonesia: GPT-4o-mini vs SEA-LIONv3"
9. We SUPA AI Blog (2025). "Benchmarking Bahasa Indonesia LLMs: SEA-LIONv3 vs SahabatAI-v1"

### Modelli e Progetti
10. AI Singapore - SEA-LION Project: https://sea-lion.ai
11. Yellow.AI - Komodo-7B: https://tech.yellow.ai/p/komodo-7b
12. Wiz.AI - Indonesian LLM Foundation Model
13. Meta - Llama 2/3/4 Technical Reports

### Media e Analisi
14. Nature (2024). "ChatGPT has a language problem ‚Äî but science can fix it"
15. Rest of World (2024). "Indonesia is using AI to preserve some of its 700 languages"
16. Slator (2024). "Yellow.ai Researchers Create a Large Language Model for Indonesia's Languages"

### Dataset e Benchmarks
17. IndoNLP Project: https://indonlp.github.io
18. IndoPref Dataset (2025). ArXiv 2507.22159
19. IndoCareer Benchmark (2024). ArXiv 2409.08564

---

## Appendice A: Esempio Comparativo

### Query Test
```
"Saya mau buka usaha kopi di Bali. KBLI apa yang cocok?"
```

### GPT-4 Response (Problematico)
```
Untuk pendirian usaha kopi di Bali, Anda perlu mengidentifikasi
Klasifikasi Baku Lapangan Usaha Indonesia (KBLI) yang sesuai.
Adapun KBLI yang relevan untuk usaha kopi adalah:

1. KBLI 56301 - Rumah Makan dan Restoran
2. KBLI 56303 - Kafe

Anda harus melakukan pendaftaran melalui sistem Online Single
Submission (OSS) yang dikelola oleh Badan Koordinasi Penanaman
Modal (BKPM).
```

**Problemi**:
- ‚ùå Troppo formale ("Adapun", "dikelola oleh")
- ‚ùå Struttura rigida (elenco numerato)
- ‚ùå Mancanza di warmth
- ‚ùå Non conversazionale

### SahabatAI-v1 Response (Ottimale)
```
Untuk usaha kopi di Bali, KBLI yang cocok adalah 56303 (Kafe).
Kalau mau ada makanan juga, bisa pakai 56301 (Rumah Makan).

Prosesnya cukup gampang kok - tinggal daftar lewat OSS online.
Biasanya NIB langsung keluar dalam hitungan hari.

Ada rencana mau jualan beans juga atau fokus ke caf√©? Nanti bisa
pengaruhi KBLI yang dipilih üòä
```

**Kelebihan**:
- ‚úÖ Natural dan conversational
- ‚úÖ "gampang kok" - reassuring
- ‚úÖ Follow-up question - engaging
- ‚úÖ Emoji appropriato
- ‚úÖ Mix formal/informal natural

### Improvement: +85% preference da native speakers

---

## Appendice B: Technical Stack Consigliato

```yaml
Production Architecture:

Primary Model:
  - Model: SEA-LION v4 (Gemma-SEA-LION-v3-9B-IT)
  - Deployment: Self-hosted su GPU (A100 40GB) o via API
  - Context: 8K tokens
  - Cost: Open-source (hosting ~$200/month)

Fallback Chain:
  1. SahabatAI-v1 (se disponibile via API)
  2. Llama 4 Scout (10M context per query complesse)
  3. Claude Haiku 4.5 (fallback ultimo)

Supporting Services:
  - Language Register Detector (Python service)
  - Cultural Context RAG (ChromaDB)
  - Quality Evaluator (automated + human-in-loop)
  - A/B Testing Framework

Infrastructure:
  - GPU: NVIDIA A100 40GB (self-hosted) o L4 24GB (cost-effective)
  - Vector DB: ChromaDB (existing)
  - Cache: Redis per pattern caching
  - Monitoring: LangSmith o custom

Estimated Cost:
  - Self-hosted: $200-500/month (GPU rental)
  - API-based: $0.001-0.002/query (SEA-LION pricing TBD)
  - Storage: $50/month (vectors + logs)
  - Total: $300-600/month (vs $2K+/month for GPT-4 heavy usage)
```

---

**Fine Documento**

---

**Prossimi Step Consigliati**:
1. Review di questo documento con team tecnico e business
2. Decision su quale modello regionale testare per primo
3. Setup ambiente di test per SEA-LION v4 / SahabatAI-v1
4. Kick-off Fase 1 con target: 2 settimane
