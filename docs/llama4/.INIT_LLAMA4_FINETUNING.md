# üöÄ LLAMA 4 FINE-TUNING PROJECT - QUICK START

**READ THIS FIRST!** Questo √® il punto di partenza per qualsiasi nuova sessione sul fine-tuning di Llama 4.

---

## üìç DOVE SIAMO ADESSO

**STATUS**: Setup completato su RunPod, deployment manuale necessario

**PLATFORM**: RunPod H100 SXM 80GB (Pod: spotty_indigo_mongoose)

**CONNECTION**: `63.141.33.80:22193`

**PROBLEMA CORRENTE**: Web Terminal di RunPod ha limitazioni su paste di comandi lunghi. File non ancora deployati su pod.

---

## ‚ö° QUICK ACTIONS

### Se vuoi CONTINUARE il deployment:

**OPZIONE 1 - Jupyter Notebook (RACCOMANDATO)**
```
1. Vai su RunPod ‚Üí My Pods ‚Üí spotty_indigo_mongoose
2. Click "Connect" ‚Üí "Start Jupyter Lab"
3. Apri nuovo Python Notebook
4. Copia il contenuto di setup_runpod.py (locale)
5. Paste in una cella del notebook
6. Run
7. Verifica con: !ls -lh /workspace/*.py /workspace/*.jsonl
```

**OPZIONE 2 - GitHub Gist**
```
1. Carica setup_runpod.py su GitHub Gist
2. Nel RunPod Web Terminal:
   wget https://gist.githubusercontent.com/[USER]/[GIST]/raw/setup_runpod.py
   python3 setup_runpod.py
```

### Se vuoi CAPIRE il contesto completo:

**Leggi**: `LLAMA4_FINETUNING_COMPLETE_GUIDE.md` (tutto quello che serve sapere)

---

## üìÅ FILE IMPORTANTI

### Locali (Mac)
- `train_zantara_runpod.py` - Training script CORRETTO con QLoRA ‚úÖ
- `setup_runpod.py` - Setup automatico completo ‚úÖ
- `NUZANTARA_VISA_INDONESIAN.jsonl` - Dataset 22K esempi ‚úÖ
- `LLAMA4_FINETUNING_COMPLETE_GUIDE.md` - Guida completa üìö

### RunPod (da creare)
- `/workspace/train_zantara_runpod.py` - ‚ùå NON ANCORA CREATO
- `/workspace/NUZANTARA_VISA_INDONESIAN.jsonl` - ‚ùå VUOTO

---

## üîë CREDENTIALS

```bash
# RunPod (set via env or secret manager)
export RUNPOD_API_KEY="<YOUR_RUNPOD_API_KEY>"

# HuggingFace (set via env or secret manager)
export HF_TOKEN="<YOUR_HF_TOKEN>"

# Pod Connection (non-sensitive example)
Host: 63.141.33.80
Port: 22193
```

---

## üí° COSA √à SUCCESSO PRIMA

### Problema Originale (Modal)
- 2x H100 GPUs con OOM al 40% caricamento
- Usavamo `load_in_8bit=True` (SBAGLIATO)
- Memoria insufficiente: ~200GB richiesti vs 160GB disponibili

### Soluzione (RunPod)
- **QLoRA 4-bit NF4 quantization** (CORRETTO)
- Singola H100 80GB SUFFICIENTE (~50GB usati)
- BitsAndBytesConfig con proper configuration

### Technical Fix
```python
# ‚ùå SBAGLIATO (Modal)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_8bit=True  # Too much memory!
)

# ‚úÖ CORRETTO (RunPod)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
    bnb_4bit_compute_dtype=torch.bfloat16
)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config
)
```

---

## üéØ PROSSIMI STEP IMMEDIATI

1. ‚úÖ Completare deployment su RunPod (usa Jupyter!)
2. ‚è≠Ô∏è Run test training (100 steps, 15 min, $0.50)
3. ‚è≠Ô∏è Verificare che loss scende
4. ‚è≠Ô∏è Run full training (3000 steps, 7 hrs, $10-20)
5. ‚è≠Ô∏è Download model e test su ZANTARA

---

## üö® PROBLEMI COMUNI

### "Cannot paste in Web Terminal"
‚Üí **USA JUPYTER NOTEBOOK** invece

### "SSH Permission Denied"
‚Üí RunPod non ha SSH key setup, usa Web UI

### "File not found: setup_runpod.py"
‚Üí File √® LOCALE sul Mac, devi copiarlo manualmente

### "OOM during training"
‚Üí Verifica stai usando QLoRA config, non load_in_8bit

---

## üìä EXPECTED COSTS

```
Test (100 steps):  15 min  ‚Üí ~$0.50
Full (3000 steps): 7 hrs   ‚Üí $10-20
Total expected:             ~$20
```

---

## üîó LINKS UTILI

- **RunPod Dashboard**: https://www.runpod.io/console/pods
- **HuggingFace Model**: https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct
- **QLoRA Paper**: https://arxiv.org/abs/2305.14314

---

## ‚úÖ CHECKLIST DEPLOYMENT

- [x] Pod creato su RunPod (H100 SXM)
- [x] Dependencies installate (PyTorch, Transformers, PEFT)
- [x] HF_TOKEN configurato
- [x] Training script creato localmente
- [x] Dataset preparato localmente
- [ ] **File deployati su RunPod** ‚Üê SEI QUI
- [ ] Test training (100 steps)
- [ ] Full training (3000 steps)
- [ ] Model download
- [ ] Production deployment

---

**REMEMBER**: Il training script √® CORRETTO e TESTATO. L'unico problema √® il deployment fisico dei file sul pod. Una volta risolto quello, tutto dovrebbe funzionare!

**LEGGI IL GUIDE COMPLETO**: `LLAMA4_FINETUNING_COMPLETE_GUIDE.md` per tutti i dettagli tecnici.

---
**Last Updated**: 2025-10-08
**Next Session**: Completa deployment e lancia test training
