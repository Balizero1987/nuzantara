#!/bin/bash

# ZANTARA Spark Integration Script
# Integrates Apache Spark with existing PostgreSQL + ChromaDB + Redis architecture

set -e

echo "üöÄ Starting ZANTARA Spark Integration..."

# Check if Docker network exists
if ! docker network ls | grep -q zantara-network; then
    echo "üì° Creating ZANTARA network..."
    docker network create zantara-network
fi

# Start Spark cluster
echo "üî• Starting Spark cluster..."
docker-compose -f docker-compose.spark.yml up -d

# Wait for Spark master to be ready
echo "‚è≥ Waiting for Spark master..."
until curl -s http://localhost:8080 > /dev/null; do
    echo "   Waiting for Spark master UI..."
    sleep 5
done

echo "‚úÖ Spark master is ready!"

# Install Python dependencies
echo "üì¶ Installing Python dependencies..."
pip install pyspark psycopg2-binary redis requests

# Set environment variables
export DB_HOST=${DB_HOST:-localhost}
export DB_NAME=${DB_NAME:-zantara}
export DB_USER=${DB_USER:-postgres}
export DB_PASSWORD=${DB_PASSWORD:-password}
export REDIS_HOST=${REDIS_HOST:-localhost}
export REDIS_PORT=${REDIS_PORT:-6379}
export CHROMADB_URL=${CHROMADB_URL:-http://localhost:8000}
export RAG_BACKEND_URL=${RAG_BACKEND_URL:-http://localhost:8080}

# Run Spark job
echo "‚ö° Running Spark KBLI processor..."
python src/spark/kbli_processor.py

echo "üéâ Spark integration completed successfully!"
echo ""
echo "üìä Access Spark UI at: http://localhost:8080"
echo "üìà Access Spark History at: http://localhost:18080"

# Show cluster status
echo ""
echo "üîç Spark Cluster Status:"
docker-compose -f docker-compose.spark.yml ps