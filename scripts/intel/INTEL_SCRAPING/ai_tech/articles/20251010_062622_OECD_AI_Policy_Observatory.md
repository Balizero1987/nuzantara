# The OECD Artificial Intelligence Policy Observatory - OECD.AI

**Source**: OECD AI Policy Observatory
**URL**: https://oecd.ai
**Scraped**: 2025-10-10T06:26:20.140319
**Category**: ai_tech

---

Policies, data and analysis for trustworthy artificial intelligence

In July 2024, the GPAI initiative and OECD member countries’ work on AI joined forces under the GPAI brand to create an integrated partnership. Find out more.

Featured
Event
Digital Trust Convention 2025

Join the second edition, held in Canada at Mila AI research institute in Montreal.

6 -7 November 2025

Report
AI openness: A primer for policymakers

Explores the concept of the AI openness spectrum and relevant terminology.

Report

Learn
Read about the GPAI – OECD integrated partnership

G7 reporting
Participate in the G7 reporting framework for organisations developing advanced AI systems

GPAI Summit
GPAI Belgrade Ministerial Declaration

Latest posts on the OECD AI Wonk

Visit the AI Wonk

Academia
There are many ways to minimise water use related to AI operations, but they may not be what you think

AI is surging not just in popularity and investment, but also in its physical scale. Behind every chatbot query or AI-powered service are data centres that consume large amounts of electricity, genera...

October 7, 2025 — 7 min read

Intergovernmental
Quantum and AI: A powerful partnership for the next digital revolution

Quantum and AI together could drive the next digital revolution. Here are insights on opportunities, challenges, and future breakthroughs.

October 2, 2025 — 5 min read

Academia
From risk to resilience: No-code AI governance in the Global South

No-code AI governance empowers the Global South to build local guardrails, bridge skills gaps, and enable inclusive, resilient adoption.

September 30, 2025 — 8 min read

Intergovernmental
G7 AI transparency reporting: Ten insights for AI governance and risk management

Discover key insights from the G7 Hiroshima AI Process transparency reports on AI governance, risk management, safety, and accountability.

September 25, 2025 — 6 min read

Intergovernmental
AI openness: Balancing innovation, transparency and risk in open-weight models

In August 2025, OpenAI announced GPT-OSS, a family of open-weight models that provide public access to the trained parameters of a frontier-level AI system. This gives a new sense of urgency to the de...

August 28, 2025 — 6 min read

Intergovernmental
Introducing the OECD.AI Policy Navigator

The Policy Navigator simplifies the process of tracking and submitting AI policy information, while dramatically increasing coverage and usability.

July 10, 2025 — 2 min read

Intergovernmental
Shaping trustworthy AI: Early insights from the Hiroshima AI Process Reporting Framework

the OECD worked with experts from government, business, academia, and civil society to design a voluntary reporting framework.

June 11, 2025 — 5 min read

Business
A milestone in international AI transparency: The OECD publishes initial submissions from the G7 Hiroshima AI Process Reporting Framework

The publication of these reports reflects the first tangible outcomes of the reporting mechanism launched in February 2025.

April 24, 2025 — 2 min read

Intergovernmental
From deepfake scams to biased AI: How incident reporting can help us keep ahead of AI’s harms

If we can understand the origins of AI incidents, we have a greater chance of devising effective responses.

March 4, 2025 — 5 min read

Intergovernmental
Artificial intelligence and intellectual property: Navigating the challenges of data scraping

The Global Partnership on AI (GPAI) has released a new report examining the intellectual property (IP) implications of how organisations collect and use data to train AI systems, with a particular foc...

February 14, 2025 — 5 min read

Priority Issues

AI Futures
AI Compute and the Environment
AI Risk & Accountability
AI & Health
AI Incidents
AI, Data & Privacy
Generative AI
OECD AI Incidents Monitor (AIM)

AIM tracks AI incidents in the global press for valuable insights into existing AI risks.

Explore AIM
OECD Catalogue of Tools & Metrics for Trustworthy AI

To help AI actors develop and use trustworthy AI systems and applications that respect human rights and are fair, transparent, explainable, robust, secure and safe.

Visit the Catalogue
